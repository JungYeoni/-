{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hooeOF4s9p8k",
        "outputId": "4577c1b9-8e56-4153-f88b-c5a311e13415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ ì‚¬ìš© ë””ë°”ì´ìŠ¤: cpu\n",
            "âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "import torch\n",
        "import warnings\n",
        "import os\n",
        "import pickle\n",
        "import json\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# ì„¤ì •\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ğŸš€ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n",
        "\n",
        "# ì‹œë“œ ì„¤ì •\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# í•œê¸€ í°íŠ¸ ì„¤ì • (í•„ìš”ì‹œ ìˆ˜ì •)\n",
        "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
        "plt.rcParams[\"axes.unicode_minus\"] = False\n",
        "\n",
        "print(\"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43ULP4T6_B8o",
        "outputId": "e3fe020e-d868-4144-b7de-ad5b57128cb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… MusicEmotionClassifier ëª¨ë¸ ì •ì˜ ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# In[2]:\n",
        "class MusicEmotionClassifier(nn.Module):\n",
        "    \"\"\"ìŒì•… ê°ì • ë¶„ë¥˜ë¥¼ ìœ„í•œ ì‹ ê²½ë§ ëª¨ë¸\"\"\"\n",
        "    \n",
        "    def __init__(self, input_dim, hidden_layers=[256, 128, 64], num_classes=10, dropout=0.3):\n",
        "        super(MusicEmotionClassifier, self).__init__()\n",
        "        \n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "        \n",
        "        # íˆë“  ë ˆì´ì–´ êµ¬ì„±\n",
        "        for i, hidden_dim in enumerate(hidden_layers):\n",
        "            layers.extend([\n",
        "                nn.Linear(prev_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout if i < len(hidden_layers)-1 else dropout/2)\n",
        "            ])\n",
        "            prev_dim = hidden_dim\n",
        "        \n",
        "        # ì¶œë ¥ ë ˆì´ì–´\n",
        "        layers.extend([\n",
        "            nn.Linear(prev_dim, num_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        ])\n",
        "        \n",
        "        self.network = nn.Sequential(*layers)\n",
        "        self._initialize_weights()\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”\"\"\"\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                nn.init.xavier_uniform_(module.weight)\n",
        "                nn.init.zeros_(module.bias)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "print(\"âœ… MusicEmotionClassifier ëª¨ë¸ ì •ì˜ ì™„ë£Œ\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5NjowWf_YXb",
        "outputId": "6e1f92d9-8aeb-4b07-8411-5dd4162ab634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ê°ì • ì„¤ì • ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# ## 3. ê°ì • ë§¤í•‘ ë° ë¶„ë¥˜ ê·œì¹™ ì •ì˜\n",
        "\n",
        "# In[3]:\n",
        "class EmotionConfig:\n",
        "    \"\"\"ê°ì • ì„¤ì • ë° ë§¤í•‘ í´ë˜ìŠ¤\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        # ê°ì • ì¹´í…Œê³ ë¦¬ ì •ì˜ (ì¸ì‚¬ì´ë“œì•„ì›ƒ 2 ê¸°ë°˜)\n",
        "        self.emotions = {\n",
        "            'joy': {'valence': (0.8, 1.0), 'energy_weight': 0.7, 'label': 'ê¸°ì¨ì´'},\n",
        "            'sadness': {'valence': (0.0, 0.25), 'energy_weight': 0.2, 'label': 'ìŠ¬í””ì´'},\n",
        "            'boredom': {'valence': (0.4, 0.6), 'energy_weight': 0.1, 'label': 'ë”°ë¶„ì´'},\n",
        "            'anxiety': {'valence': (0.1, 0.4), 'energy_weight': 0.5, 'label': 'ì†Œì‹¬ì´'},\n",
        "            'anger': {'valence': (0.0, 0.3), 'energy_weight': 0.8, 'label': 'ë²„ëŸ­ì´'},\n",
        "            'grumpy': {'valence': (0.3, 0.5), 'energy_weight': 0.5, 'label': 'ê¹Œì¹ ì´'},\n",
        "            'fear': {'valence': (0.0, 0.2), 'energy_weight': 0.9, 'label': 'ë¶ˆì•ˆì´'},\n",
        "            'embarrassment': {'valence': (0.5, 0.75), 'energy_weight': 0.3, 'label': 'ë‹¹í™©ì´'},\n",
        "            'envy': {'valence': (0.2, 0.4), 'energy_weight': 0.4, 'label': 'ë¶€ëŸ½ì´'},\n",
        "            'calm': {'valence': (0.4, 0.75), 'energy_weight': 0.3, 'label': 'í‰ì˜¨'},\n",
        "        }\n",
        "        \n",
        "        # í•œêµ­ì–´ ê°ì • í‚¤ì›Œë“œ ë§¤í•‘\n",
        "        self.korean_emotion_map = {\n",
        "            # ê¸°ì¨ ê´€ë ¨\n",
        "            'ê¸°ì¨': 'joy', 'í™˜í¬': 'joy', 'ì¦ê±°ì›€': 'joy', 'í–‰ë³µ': 'joy', 'ë§Œì¡±': 'joy',\n",
        "            'ì‹ ë‚˜ëŠ”': 'joy', 'ê¸°ìœ': 'joy', 'ì¦ê±°ìš´': 'joy', 'í–‰ë³µí•œ': 'joy', 'ì¢‹ì€': 'joy',\n",
        "            'ì„¤ë ˜': 'joy', 'ìƒì¾Œ': 'joy', 'í™œê¸°': 'joy', 'ìµœê³ ': 'joy', 'ì™„ë²½': 'joy',\n",
        "            \n",
        "            # ìŠ¬í”” ê´€ë ¨  \n",
        "            'ìŠ¬í””': 'sadness', 'ìš°ìš¸': 'sadness', 'ì¢Œì ˆ': 'sadness', 'ë¹„ì°¸': 'sadness',\n",
        "            'ìŠ¬í”ˆ': 'sadness', 'ìš°ìš¸í•œ': 'sadness', 'ì™¸ë¡œìš´': 'sadness', 'ì•”ìš¸': 'sadness',\n",
        "            'ê·¸ë¦¬ì›€': 'sadness', 'ì•„ì‰¬ì›€': 'sadness', 'í›„íšŒ': 'sadness', 'ì‹¤ë§': 'sadness',\n",
        "            \n",
        "            # ì§€ë£¨í•¨ ê´€ë ¨\n",
        "            'ì§€ë£¨í•¨': 'boredom', 'ë”°ë¶„': 'boredom', 'ì‹¬ì‹¬': 'boredom', 'ë¬´ê¸°ë ¥': 'boredom',\n",
        "            'ì§€ë£¨í•œ': 'boredom', 'ì‹¬ì‹¬í•œ': 'boredom', 'ë”°ë¶„í•œ': 'boredom', 'ì¬ë¯¸ì—†': 'boredom',\n",
        "            \n",
        "            # ë¶ˆì•ˆ ê´€ë ¨\n",
        "            'ë¶ˆì•ˆ': 'anxiety', 'ê±±ì •': 'anxiety', 'ì´ˆì¡°': 'anxiety', 'ê¸´ì¥': 'anxiety',\n",
        "            'ìŠ¤íŠ¸ë ˆìŠ¤': 'anxiety', 'ë‹µë‹µ': 'anxiety', 'ë¶ˆì•ˆí•œ': 'anxiety', 'ê±±ì •ë˜ëŠ”': 'anxiety',\n",
        "            \n",
        "            # ë¶„ë…¸ ê´€ë ¨\n",
        "            'í™”ë‚¨': 'anger', 'ë¶„ë…¸': 'anger', 'ì§œì¦': 'anger', 'ë²„ëŸ­': 'anger',\n",
        "            'í™”ë‚œ': 'anger', 'ì§œì¦ë‚˜ëŠ”': 'anger', 'ì—´ë°›': 'anger', 'ë¹¡ì¹œ': 'anger',\n",
        "            \n",
        "            # ê¹Œì¹ í•¨ ê´€ë ¨\n",
        "            'ê¹Œì¹ ': 'grumpy', 'ì˜ˆë¯¼': 'grumpy', 'ë¶ˆì¾Œ': 'grumpy',\n",
        "            \n",
        "            # ë‘ë ¤ì›€ ê´€ë ¨\n",
        "            'ë‘ë ¤ì›€': 'fear', 'ê³µí¬': 'fear', 'ë¬´ì„œì›€': 'fear', 'ê²': 'fear',\n",
        "            'ë¬´ì„œìš´': 'fear', 'ë‘ë ¤ìš´': 'fear', 'ê²ë‚˜ëŠ”': 'fear',\n",
        "            \n",
        "            # ë‹¹í™© ê´€ë ¨\n",
        "            'ë‹¹í™©': 'embarrassment', 'ì–´ìƒ‰': 'embarrassment', 'ë¯¼ë§': 'embarrassment',\n",
        "            \n",
        "            # ë¶€ëŸ¬ì›€ ê´€ë ¨\n",
        "            'ë¶€ëŸ¬ì›€': 'envy', 'ì§ˆíˆ¬': 'envy',\n",
        "            \n",
        "            # í‰ì˜¨ ê´€ë ¨\n",
        "            'í‰ì˜¨': 'calm', 'ì°¨ë¶„': 'calm', 'ì•ˆì •': 'calm', 'í¸ì•ˆ': 'calm',\n",
        "            'ì—¬ìœ ': 'calm', 'ëŠê¸‹': 'calm', 'í‰ì˜¨í•œ': 'calm', 'ì°¨ë¶„í•œ': 'calm',\n",
        "        }\n",
        "    \n",
        "    def classify_emotion(self, valence, energy):\n",
        "        \"\"\"Valence-Energy ê°’ìœ¼ë¡œ ê°ì • ë¶„ë¥˜\"\"\"\n",
        "        # ê°ì • ë¶„ë¥˜ ë¡œì§ (ìˆœì„œ ì¤‘ìš”)\n",
        "        if valence >= 0.8 and energy >= 0.7:\n",
        "            return 'joy'\n",
        "        elif valence < 0.2 and energy >= 0.85:\n",
        "            return 'fear'\n",
        "        elif valence < 0.3 and energy >= 0.7:\n",
        "            return 'anger'\n",
        "        elif 0.2 <= valence < 0.4 and energy >= 0.4:\n",
        "            return 'envy'\n",
        "        elif 0.1 <= valence < 0.4 and energy >= 0.5:\n",
        "            return 'anxiety'\n",
        "        elif valence < 0.25 and energy < 0.3:\n",
        "            return 'sadness'\n",
        "        elif 0.4 <= valence < 0.6 and energy < 0.2:\n",
        "            return 'boredom'\n",
        "        elif 0.3 <= valence < 0.5 and energy >= 0.5:\n",
        "            return 'grumpy'\n",
        "        elif 0.5 <= valence < 0.75 and energy < 0.4:\n",
        "            return 'embarrassment'\n",
        "        else:\n",
        "            return 'calm'\n",
        "    \n",
        "    def get_emotion_label(self, emotion_key):\n",
        "        \"\"\"ê°ì • í‚¤ì— ëŒ€í•œ í•œêµ­ì–´ ë¼ë²¨ ë°˜í™˜\"\"\"\n",
        "        return self.emotions.get(emotion_key, {'label': 'ì•Œ ìˆ˜ ì—†ìŒ'})['label']\n",
        "    \n",
        "    def map_korean_emotion(self, korean_text):\n",
        "        \"\"\"í•œêµ­ì–´ í…ìŠ¤íŠ¸ì—ì„œ ê°ì • ë§¤í•‘\"\"\"\n",
        "        for keyword, emotion in self.korean_emotion_map.items():\n",
        "            if keyword in korean_text:\n",
        "                return emotion, keyword\n",
        "        return None, None\n",
        "\n",
        "# ì „ì—­ ì„¤ì • ê°ì²´ ìƒì„±\n",
        "emotion_config = EmotionConfig()\n",
        "print(\"âœ… ê°ì • ì„¤ì • ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "5nsUg1fu_dL6",
        "outputId": "5e0e8f4b-43db-4f1a-d9c9-acabcdafe0f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ë°ì´í„° ë¡œë” ì¤€ë¹„ ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# ## 4. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤\n",
        "\n",
        "# In[4]:\n",
        "class DataLoader:\n",
        "    \"\"\"ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ í´ë˜ìŠ¤\"\"\"\n",
        "    \n",
        "    def __init__(self, emotion_config):\n",
        "        self.emotion_config = emotion_config\n",
        "        self.train_df = None\n",
        "        self.test_df = None\n",
        "    \n",
        "    def load_train_data(self, file_path):\n",
        "        \"\"\"í•™ìŠµ ë°ì´í„° ë¡œë“œ (Spotify Tracks Dataset)\"\"\"\n",
        "        try:\n",
        "            if not os.path.exists(file_path):\n",
        "                print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
        "                return False\n",
        "            \n",
        "            print(f\"ğŸ“‚ í•™ìŠµ ë°ì´í„° ë¡œë”© ì¤‘: {file_path}\")\n",
        "            self.train_df = pd.read_csv(file_path)\n",
        "            \n",
        "            # ì»¬ëŸ¼ëª… ì •ë¦¬\n",
        "            self.train_df.columns = self.train_df.columns.str.strip()\n",
        "            \n",
        "            print(f\"ğŸ“Š ì›ë³¸ ë°ì´í„°: {len(self.train_df):,} íŠ¸ë™\")\n",
        "            \n",
        "            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸\n",
        "            required_cols = ['valence', 'energy', 'danceability', 'acousticness']\n",
        "            missing_cols = [col for col in required_cols if col not in self.train_df.columns]\n",
        "            \n",
        "            if missing_cols:\n",
        "                print(f\"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}\")\n",
        "                return False\n",
        "            \n",
        "            # ë°ì´í„° ì „ì²˜ë¦¬\n",
        "            self._preprocess_train_data()\n",
        "            \n",
        "            print(f\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {len(self.train_df):,} íŠ¸ë™\")\n",
        "            self._print_emotion_distribution(self.train_df, \"í•™ìŠµ\")\n",
        "            \n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def load_test_data(self, file_path):\n",
        "        \"\"\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ (Spotify YouTube Dataset)\"\"\"\n",
        "        try:\n",
        "            if not os.path.exists(file_path):\n",
        "                print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
        "                return False\n",
        "            \n",
        "            print(f\"ğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© ì¤‘: {file_path}\")\n",
        "            self.test_df = pd.read_csv(file_path)\n",
        "            \n",
        "            # ì»¬ëŸ¼ëª… ì •ë¦¬ ë° ë§¤í•‘\n",
        "            self.test_df.columns = self.test_df.columns.str.strip()\n",
        "            self._map_test_columns()\n",
        "            \n",
        "            print(f\"ğŸ“Š ì›ë³¸ ë°ì´í„°: {len(self.test_df):,} íŠ¸ë™\")\n",
        "            \n",
        "            # ë°ì´í„° ì „ì²˜ë¦¬\n",
        "            self._preprocess_test_data()\n",
        "            \n",
        "            print(f\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {len(self.test_df):,} íŠ¸ë™\")\n",
        "            self._print_emotion_distribution(self.test_df, \"í…ŒìŠ¤íŠ¸\")\n",
        "            \n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def _preprocess_train_data(self):\n",
        "        \"\"\"í•™ìŠµ ë°ì´í„° ì „ì²˜ë¦¬\"\"\"\n",
        "        # í•„ìˆ˜ ì»¬ëŸ¼ ê²°ì¸¡ê°’ ì œê±°\n",
        "        required_cols = ['valence', 'energy', 'danceability', 'acousticness']\n",
        "        self.train_df.dropna(subset=required_cols, inplace=True)\n",
        "        \n",
        "        # 0~1 ë²”ìœ„ ë°–ì˜ ê°’ ì œê±°\n",
        "        for col in required_cols:\n",
        "            self.train_df = self.train_df[\n",
        "                (self.train_df[col] >= 0) & (self.train_df[col] <= 1)\n",
        "            ]\n",
        "        \n",
        "        # ê°ì • ë¶„ë¥˜ ì ìš©\n",
        "        self.train_df['emotion_cat'] = self.train_df.apply(\n",
        "            lambda row: self.emotion_config.classify_emotion(row['valence'], row['energy']), \n",
        "            axis=1\n",
        "        )\n",
        "    \n",
        "    def _preprocess_test_data(self):\n",
        "        \"\"\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬\"\"\"\n",
        "        # ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„± í™•ì¸\n",
        "        audio_features = ['valence', 'energy', 'danceability', 'acousticness', \n",
        "                         'instrumentalness', 'liveness', 'speechiness', 'loudness', 'tempo']\n",
        "        available_features = [f for f in audio_features if f in self.test_df.columns]\n",
        "        \n",
        "        # ê²°ì¸¡ê°’ ì œê±°\n",
        "        self.test_df.dropna(subset=available_features, inplace=True)\n",
        "        \n",
        "        # 0~1 ë²”ìœ„ ì •ê·œí™” (í•´ë‹¹í•˜ëŠ” íŠ¹ì„±ë“¤ë§Œ)\n",
        "        normalized_features = ['valence', 'energy', 'danceability', 'acousticness']\n",
        "        for col in normalized_features:\n",
        "            if col in self.test_df.columns:\n",
        "                self.test_df[col] = pd.to_numeric(self.test_df[col], errors='coerce')\n",
        "                self.test_df = self.test_df[\n",
        "                    (self.test_df[col] >= 0) & (self.test_df[col] <= 1)\n",
        "                ].copy()\n",
        "        \n",
        "        # ë‹¤ì‹œ ê²°ì¸¡ê°’ ì œê±°\n",
        "        self.test_df.dropna(subset=available_features, inplace=True)\n",
        "        \n",
        "        # ê°ì • ë¶„ë¥˜ ì ìš©\n",
        "        if 'valence' in self.test_df.columns and 'energy' in self.test_df.columns:\n",
        "            self.test_df['emotion_cat'] = self.test_df.apply(\n",
        "                lambda row: self.emotion_config.classify_emotion(row['valence'], row['energy']), \n",
        "                axis=1\n",
        "            )\n",
        "        else:\n",
        "            self.test_df['emotion_cat'] = 'calm'\n",
        "    \n",
        "    def _map_test_columns(self):\n",
        "        \"\"\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì»¬ëŸ¼ëª… ë§¤í•‘\"\"\"\n",
        "        column_mapping = {\n",
        "            'Track': 'track_name',\n",
        "            'Artist': 'track_artist',\n",
        "            'Danceability': 'danceability',\n",
        "            'Energy': 'energy',\n",
        "            'Valence': 'valence',\n",
        "            'Acousticness': 'acousticness',\n",
        "            'Instrumentalness': 'instrumentalness',\n",
        "            'Liveness': 'liveness',\n",
        "            'Speechiness': 'speechiness',\n",
        "            'Loudness': 'loudness',\n",
        "            'Tempo': 'tempo'\n",
        "        }\n",
        "        \n",
        "        for old_name, new_name in column_mapping.items():\n",
        "            if old_name in self.test_df.columns:\n",
        "                self.test_df.rename(columns={old_name: new_name}, inplace=True)\n",
        "    \n",
        "    def _print_emotion_distribution(self, df, data_type):\n",
        "        \"\"\"ê°ì • ë¶„í¬ ì¶œë ¥\"\"\"\n",
        "        if 'emotion_cat' in df.columns:\n",
        "            print(f\"ğŸ“ˆ {data_type} ë°ì´í„° ê°ì • ë¶„í¬:\")\n",
        "            emotion_counts = df['emotion_cat'].value_counts()\n",
        "            for emotion, count in emotion_counts.items():\n",
        "                label = self.emotion_config.get_emotion_label(emotion)\n",
        "                print(f\"   - {label}: {count:,} íŠ¸ë™\")\n",
        "    \n",
        "    def get_common_features(self):\n",
        "        \"\"\"í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ê³µí†µ íŠ¹ì„± ë°˜í™˜\"\"\"\n",
        "        if self.train_df is None or self.test_df is None:\n",
        "            return []\n",
        "        \n",
        "        standard_features = ['valence', 'energy', 'danceability', 'acousticness',\n",
        "                           'instrumentalness', 'liveness', 'speechiness', 'loudness', 'tempo']\n",
        "        \n",
        "        common_features = list(\n",
        "            set(standard_features) & \n",
        "            set(self.train_df.columns) & \n",
        "            set(self.test_df.columns)\n",
        "        )\n",
        "        \n",
        "        return common_features\n",
        "\n",
        "# ë°ì´í„° ë¡œë” ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
        "data_loader = DataLoader(emotion_config)\n",
        "print(\"âœ… ë°ì´í„° ë¡œë” ì¤€ë¹„ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QigRXJfm_fsp",
        "outputId": "62e9c3d2-66d1-4bfa-d6b1-301cdfff05fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“‚ ë°ì´í„° ë¡œë”© ì‹œì‘...\n",
            "í•™ìŠµ ë°ì´í„°: C:\\Users\\USER\\OneDrive\\ë¬¸ì„œ\\GitHub\\-\\dataset\\Spotify_Tracks_Dataset.csv\n",
            "í…ŒìŠ¤íŠ¸ ë°ì´í„°: C:\\Users\\USER\\OneDrive\\ë¬¸ì„œ\\GitHub\\-\\dataset\\Spotify_Youtube.csv\n",
            "ğŸ“‚ í•™ìŠµ ë°ì´í„° ë¡œë”© ì¤‘: C:\\Users\\USER\\OneDrive\\ë¬¸ì„œ\\GitHub\\-\\dataset\\Spotify_Tracks_Dataset.csv\n",
            "ğŸ“Š ì›ë³¸ ë°ì´í„°: 114,000 íŠ¸ë™\n",
            "âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: 114,000 íŠ¸ë™\n",
            "ğŸ“ˆ í•™ìŠµ ë°ì´í„° ê°ì • ë¶„í¬:\n",
            "   - í‰ì˜¨: 52,158 íŠ¸ë™\n",
            "   - ë¶€ëŸ½ì´: 16,053 íŠ¸ë™\n",
            "   - ê¹Œì¹ ì´: 9,935 íŠ¸ë™\n",
            "   - ê¸°ì¨ì´: 9,624 íŠ¸ë™\n",
            "   - ë²„ëŸ­ì´: 7,494 íŠ¸ë™\n",
            "   - ìŠ¬í””ì´: 7,240 íŠ¸ë™\n",
            "   - ë¶ˆì•ˆì´: 5,133 íŠ¸ë™\n",
            "   - ë‹¹í™©ì´: 3,055 íŠ¸ë™\n",
            "   - ì†Œì‹¬ì´: 2,324 íŠ¸ë™\n",
            "   - ë”°ë¶„ì´: 984 íŠ¸ë™\n",
            "ğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© ì¤‘: C:\\Users\\USER\\OneDrive\\ë¬¸ì„œ\\GitHub\\-\\dataset\\Spotify_Youtube.csv\n",
            "ğŸ“Š ì›ë³¸ ë°ì´í„°: 20,718 íŠ¸ë™\n",
            "âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: 20,716 íŠ¸ë™\n",
            "ğŸ“ˆ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°ì • ë¶„í¬:\n",
            "   - í‰ì˜¨: 10,871 íŠ¸ë™\n",
            "   - ë¶€ëŸ½ì´: 3,069 íŠ¸ë™\n",
            "   - ê¹Œì¹ ì´: 2,015 íŠ¸ë™\n",
            "   - ê¸°ì¨ì´: 2,001 íŠ¸ë™\n",
            "   - ìŠ¬í””ì´: 892 íŠ¸ë™\n",
            "   - ë²„ëŸ­ì´: 710 íŠ¸ë™\n",
            "   - ë‹¹í™©ì´: 436 íŠ¸ë™\n",
            "   - ì†Œì‹¬ì´: 429 íŠ¸ë™\n",
            "   - ë¶ˆì•ˆì´: 200 íŠ¸ë™\n",
            "   - ë”°ë¶„ì´: 93 íŠ¸ë™\n",
            "âœ… ëª¨ë“  ë°ì´í„° ë¡œë”© ì™„ë£Œ\n",
            "ğŸ”§ ê³µí†µ íŠ¹ì„± (9ê°œ): ['tempo', 'valence', 'acousticness', 'loudness', 'speechiness', 'danceability', 'liveness', 'instrumentalness', 'energy']\n"
          ]
        }
      ],
      "source": [
        "# ## 5. ë°ì´í„° ë¡œë“œ ì‹¤í–‰\n",
        "\n",
        "# In[5]:\n",
        "# ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì • \n",
        "TRAIN_DATA_PATH = r\"C:\\Users\\USER\\OneDrive\\ë¬¸ì„œ\\GitHub\\-\\dataset\\Spotify_Tracks_Dataset.csv\"\n",
        "TEST_DATA_PATH = r\"C:\\Users\\USER\\OneDrive\\ë¬¸ì„œ\\GitHub\\-\\dataset\\Spotify_Youtube.csv\"\n",
        "\n",
        "print(\"ğŸ“‚ ë°ì´í„° ë¡œë”© ì‹œì‘...\")\n",
        "print(f\"í•™ìŠµ ë°ì´í„°: {TRAIN_DATA_PATH}\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {TEST_DATA_PATH}\")\n",
        "\n",
        "# ì‹¤ì œ ì‹¤í–‰ (íŒŒì¼ì´ ì¡´ì¬í•  ë•Œ)\n",
        "train_loaded = data_loader.load_train_data(TRAIN_DATA_PATH)\n",
        "test_loaded = data_loader.load_test_data(TEST_DATA_PATH)\n",
        "\n",
        "if train_loaded and test_loaded:\n",
        "    print(\"âœ… ëª¨ë“  ë°ì´í„° ë¡œë”© ì™„ë£Œ\")\n",
        "    common_features = data_loader.get_common_features()\n",
        "    print(f\"ğŸ”§ ê³µí†µ íŠ¹ì„± ({len(common_features)}ê°œ): {common_features}\")\n",
        "else:\n",
        "    print(\"âš ï¸ ë°ì´í„° íŒŒì¼ì„ í™•ì¸í•˜ê³  ê²½ë¡œë¥¼ ìˆ˜ì •í•´ì£¼ì„¸ìš”\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7h7EZT-BRjD",
        "outputId": "1f11ab02-8c03-4817-ae4c-7b5e3290251b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...\n",
            "ğŸ“Š ì „ì²˜ë¦¬ ê²°ê³¼:\n",
            "   í•™ìŠµ ë°ì´í„°: 114,000 ìƒ˜í”Œ, 9 íŠ¹ì„±\n",
            "   í…ŒìŠ¤íŠ¸ ë°ì´í„°: 20,716 ìƒ˜í”Œ, 9 íŠ¹ì„±\n",
            "   ê°ì • í´ë˜ìŠ¤: ['anger', 'anxiety', 'boredom', 'calm', 'embarrassment', 'envy', 'fear', 'grumpy', 'joy', 'sadness']\n",
            "âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        " ## 6. ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¤€ë¹„\n",
        "\n",
        "# In[6]:\n",
        "class DataPreprocessor:\n",
        "    \"\"\"ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.imputation_means = None\n",
        "        self.common_features = None\n",
        "    \n",
        "    def prepare_data(self, train_df, test_df, common_features):\n",
        "        \"\"\"í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„\"\"\"\n",
        "        print(\"ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...\")\n",
        "        \n",
        "        self.common_features = common_features\n",
        "        \n",
        "        # ë°ì´í„° í•„í„°ë§\n",
        "        train_cols = common_features + ['emotion_cat']\n",
        "        test_cols = common_features + ['emotion_cat']\n",
        "        \n",
        "        train_filtered = train_df[train_cols].copy()\n",
        "        test_filtered = test_df[test_cols].copy()\n",
        "        \n",
        "        # ë¬´í•œê°’ ì²˜ë¦¬\n",
        "        train_filtered.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "        test_filtered.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "        \n",
        "        # ê²°ì¸¡ê°’ ì²˜ë¦¬ (í•™ìŠµ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ í‰ê· ê°’ ê³„ì‚°)\n",
        "        self.imputation_means = train_filtered[common_features].mean()\n",
        "        \n",
        "        train_clean = train_filtered.fillna(self.imputation_means)\n",
        "        test_clean = test_filtered.fillna(self.imputation_means)\n",
        "        \n",
        "        # íŠ¹ì„±ê³¼ ë¼ë²¨ ë¶„ë¦¬\n",
        "        X_train = train_clean[common_features].values\n",
        "        y_train = self.label_encoder.fit_transform(train_clean['emotion_cat'])\n",
        "        \n",
        "        X_test = test_clean[common_features].values\n",
        "        y_test = self.label_encoder.transform(test_clean['emotion_cat'])\n",
        "        \n",
        "        # ìŠ¤ì¼€ì¼ë§\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "        \n",
        "        print(f\"ğŸ“Š ì „ì²˜ë¦¬ ê²°ê³¼:\")\n",
        "        print(f\"   í•™ìŠµ ë°ì´í„°: {X_train_scaled.shape[0]:,} ìƒ˜í”Œ, {X_train_scaled.shape[1]} íŠ¹ì„±\")\n",
        "        print(f\"   í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test_scaled.shape[0]:,} ìƒ˜í”Œ, {X_test_scaled.shape[1]} íŠ¹ì„±\")\n",
        "        print(f\"   ê°ì • í´ë˜ìŠ¤: {list(self.label_encoder.classes_)}\")\n",
        "        \n",
        "        return X_train_scaled, y_train, X_test_scaled, y_test\n",
        "    \n",
        "    def get_feature_names(self):\n",
        "        \"\"\"ì‚¬ìš©ëœ íŠ¹ì„±ëª… ë°˜í™˜\"\"\"\n",
        "        return self.common_features if self.common_features else []\n",
        "    \n",
        "    def get_emotion_classes(self):\n",
        "        \"\"\"ê°ì • í´ë˜ìŠ¤ ë°˜í™˜\"\"\"\n",
        "        if hasattr(self.label_encoder, 'classes_'):\n",
        "            return list(self.label_encoder.classes_)\n",
        "        return []\n",
        "\n",
        "# ì „ì²˜ë¦¬ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
        "preprocessor = DataPreprocessor()\n",
        "\n",
        "# ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆì„ ë•Œë§Œ ì „ì²˜ë¦¬ ì‹¤í–‰\n",
        "if hasattr(data_loader, 'train_df') and data_loader.train_df is not None:\n",
        "    common_features = data_loader.get_common_features()\n",
        "    if common_features:\n",
        "        X_train, y_train, X_test, y_test = preprocessor.prepare_data(\n",
        "            data_loader.train_df, \n",
        "            data_loader.test_df, \n",
        "            common_features\n",
        "        )\n",
        "        print(\"âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ\")\n",
        "    else:\n",
        "        print(\"âŒ ê³µí†µ íŠ¹ì„±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
        "else:\n",
        "    print(\"âš ï¸ ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "4wTqzv6WBUQe",
        "outputId": "bd86a6b9-28a8-45fa-d0af-a64ec5e81cd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\n",
            "ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "í•™ìŠµ ì§„í–‰:   0%|          | 0/80 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ˆ í•™ìŠµ ì‹œì‘ - 80 ì—í¬í¬, ë°°ì¹˜ í¬ê¸°: 256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "í•™ìŠµ ì§„í–‰:  25%|â–ˆâ–ˆâ–Œ       | 20/80 [01:21<03:52,  3.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì—í¬í¬ 20/80 - ì†ì‹¤: 1.5990, ì •í™•ë„: 0.864\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "í•™ìŠµ ì§„í–‰:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [02:45<03:09,  4.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì—í¬í¬ 40/80 - ì†ì‹¤: 1.5924, ì •í™•ë„: 0.870\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "í•™ìŠµ ì§„í–‰:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 42/80 [02:57<03:26,  5.43s/it]"
          ]
        }
      ],
      "source": [
        "# ## 7. ëª¨ë¸ í•™ìŠµ (ìˆ˜ì •ëœ ë²„ì „)\n",
        "\n",
        "# In[7]:\n",
        "class ModelTrainer:\n",
        "    \"\"\"ëª¨ë¸ í•™ìŠµ í´ë˜ìŠ¤\"\"\"\n",
        "    \n",
        "    def __init__(self, emotion_config, device):\n",
        "        self.emotion_config = emotion_config\n",
        "        self.device = device\n",
        "        self.model = None\n",
        "        self.training_history = []\n",
        "    \n",
        "    def train_model(self, X_train, y_train, X_test, y_test, \n",
        "                   epochs=100, batch_size=256, learning_rate=1e-3):\n",
        "        \"\"\"ëª¨ë¸ í•™ìŠµ\"\"\"\n",
        "        print(\"ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
        "        \n",
        "        # í…ì„œ ë³€í™˜\n",
        "        X_train_tensor = torch.from_numpy(X_train).float()\n",
        "        y_train_tensor = torch.from_numpy(y_train).long()\n",
        "        X_test_tensor = torch.from_numpy(X_test).float()\n",
        "        y_test_tensor = torch.from_numpy(y_test).long()\n",
        "        \n",
        "        # PyTorch DataLoaderë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì‚¬ìš© (ì¶©ëŒ ë°©ì§€)\n",
        "        from torch.utils.data import DataLoader as TorchDataLoader\n",
        "        \n",
        "        # ë°ì´í„° ë¡œë” ìƒì„±\n",
        "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "        train_dataloader = TorchDataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        \n",
        "        # ëª¨ë¸ ìƒì„±\n",
        "        input_dim = X_train.shape[1]\n",
        "        num_classes = len(np.unique(y_train))\n",
        "        \n",
        "        self.model = MusicEmotionClassifier(\n",
        "            input_dim=input_dim,\n",
        "            num_classes=num_classes\n",
        "        ).to(self.device)\n",
        "        \n",
        "        # ì˜µí‹°ë§ˆì´ì €ì™€ ì†ì‹¤í•¨ìˆ˜\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        \n",
        "        print(f\"ğŸ“ˆ í•™ìŠµ ì‹œì‘ - {epochs} ì—í¬í¬, ë°°ì¹˜ í¬ê¸°: {batch_size}\")\n",
        "        \n",
        "        # í•™ìŠµ ë£¨í”„\n",
        "        self.training_history = []\n",
        "        \n",
        "        for epoch in tqdm(range(epochs), desc=\"í•™ìŠµ ì§„í–‰\"):\n",
        "            self.model.train()\n",
        "            epoch_loss = 0.0\n",
        "            correct_predictions = 0\n",
        "            total_samples = 0\n",
        "            \n",
        "            for batch_X, batch_y in train_dataloader:\n",
        "                batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)\n",
        "                \n",
        "                # ìˆœì „íŒŒ\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = criterion(outputs, batch_y)\n",
        "                \n",
        "                # ì—­ì „íŒŒ\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                # í†µê³„ ì—…ë°ì´íŠ¸\n",
        "                epoch_loss += loss.item()\n",
        "                predicted = outputs.argmax(1)\n",
        "                correct_predictions += (predicted == batch_y).sum().item()\n",
        "                total_samples += batch_y.size(0)\n",
        "            \n",
        "            # ğŸ”§ ìˆ˜ì •ëœ ë¶€ë¶„: train_loader -> train_dataloader\n",
        "            avg_loss = epoch_loss / len(train_dataloader)\n",
        "            accuracy = correct_predictions / total_samples\n",
        "            \n",
        "            self.training_history.append({\n",
        "                'epoch': epoch + 1,\n",
        "                'loss': avg_loss,\n",
        "                'accuracy': accuracy\n",
        "            })\n",
        "            \n",
        "            # ì§„í–‰ ìƒí™© ì¶œë ¥\n",
        "            if (epoch + 1) % 20 == 0:\n",
        "                print(f\"ì—í¬í¬ {epoch+1}/{epochs} - ì†ì‹¤: {avg_loss:.4f}, ì •í™•ë„: {accuracy:.3f}\")\n",
        "        \n",
        "        print(\"âœ… í•™ìŠµ ì™„ë£Œ\")\n",
        "        \n",
        "        # ëª¨ë¸ í‰ê°€\n",
        "        self.evaluate_model(X_test_tensor.to(self.device), y_test_tensor.to(self.device))\n",
        "        \n",
        "        return self.model\n",
        "    \n",
        "    def evaluate_model(self, X_test, y_test):\n",
        "        \"\"\"ëª¨ë¸ í‰ê°€\"\"\"\n",
        "        print(\"\\nğŸ“Š ëª¨ë¸ í‰ê°€ ì‹œì‘...\")\n",
        "        \n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X_test).cpu()\n",
        "            predictions = outputs.argmax(1)\n",
        "        \n",
        "        # ì •í™•ë„ ê³„ì‚°\n",
        "        accuracy = accuracy_score(y_test.cpu(), predictions)\n",
        "        print(f\"ğŸ¯ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.4f}\")\n",
        "        \n",
        "        return accuracy\n",
        "    \n",
        "    def plot_training_history(self):\n",
        "        \"\"\"í•™ìŠµ ê³¼ì • ì‹œê°í™”\"\"\"\n",
        "        if not self.training_history:\n",
        "            print(\"í•™ìŠµ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            return\n",
        "        \n",
        "        epochs = [h['epoch'] for h in self.training_history]\n",
        "        losses = [h['loss'] for h in self.training_history]\n",
        "        accuracies = [h['accuracy'] for h in self.training_history]\n",
        "        \n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "        \n",
        "        # ì†ì‹¤ ê·¸ë˜í”„\n",
        "        ax1.plot(epochs, losses, 'b-', linewidth=2)\n",
        "        ax1.set_title('í•™ìŠµ ì†ì‹¤')\n",
        "        ax1.set_xlabel('ì—í¬í¬')\n",
        "        ax1.set_ylabel('ì†ì‹¤')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        \n",
        "        # ì •í™•ë„ ê·¸ë˜í”„\n",
        "        ax2.plot(epochs, accuracies, 'r-', linewidth=2)\n",
        "        ax2.set_title('í•™ìŠµ ì •í™•ë„')\n",
        "        ax2.set_xlabel('ì—í¬í¬')\n",
        "        ax2.set_ylabel('ì •í™•ë„')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# ëª¨ë¸ íŠ¸ë ˆì´ë„ˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
        "trainer = ModelTrainer(emotion_config, device)\n",
        "\n",
        "# í•™ìŠµ ì‹¤í–‰ ì˜ˆì‹œ (ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ìˆì„ ë•Œ)\n",
        "if 'X_train' in locals() and X_train is not None:\n",
        "    print(\"ğŸ¯ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
        "    model = trainer.train_model(X_train, y_train, X_test, y_test, epochs=80)\n",
        "    print(\"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
        "else:\n",
        "    print(\"âš ï¸ ë¨¼ì € ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•´ì£¼ì„¸ìš”.\")\n",
        "    print(\"ì‹¤í–‰ ìˆœì„œ:\")\n",
        "    print(\"1. ë°ì´í„° ë¡œë”©\")\n",
        "    print(\"2. ë°ì´í„° ì „ì²˜ë¦¬\") \n",
        "    print(\"3. ëª¨ë¸ í•™ìŠµ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš ï¸ í•™ìŠµ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•´ì£¼ì„¸ìš”.\n"
          ]
        }
      ],
      "source": [
        "# ## 8. í•™ìŠµ ê²°ê³¼ ì‹œê°í™”\n",
        "\n",
        "# In[8]:\n",
        "# í•™ìŠµ ê³¼ì • ì‹œê°í™”\n",
        "if hasattr(trainer, 'training_history') and trainer.training_history:\n",
        "    trainer.plot_training_history()\n",
        "else:\n",
        "    print(\"âš ï¸ í•™ìŠµ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•´ì£¼ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgGtsAgsBWdi",
        "outputId": "02a1a5a1-036d-49ac-9229-e6fdabf85e3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ¯ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸...\n",
            "\n",
            "[Joy ê°ì • ì¶”ì²œ ê³¡]\n",
            "  ğŸµ Your Love Is All I Need - Original Mix - Liz Torres (ìœ ì‚¬ë„: 0.990)\n",
            "  ğŸµ Tiroler Bua (Wellerman - HÃ¼ttenstyle) - Matty Valentino;DJ MOX;Ivan Fillini;Toby Tyrol;Xandl (ìœ ì‚¬ë„: 0.989)\n",
            "  ğŸµ åŠé»å¿ƒ - Grasshopper (ìœ ì‚¬ë„: 0.988)\n",
            "\n",
            "[Sadness ê°ì • ì¶”ì²œ ê³¡]\n",
            "  ğŸµ AcompÃ¡Ã±ame - Alberto Vazquez (ìœ ì‚¬ë„: 0.991)\n",
            "  ğŸµ O Holy Night - Top of the Bus (ìœ ì‚¬ë„: 0.985)\n",
            "  ğŸµ Komm Zigany (auch ich war einst ein feiner CsÃ¡rdÃ¡skavalier) - Emmerich KÃ¡lmÃ¡n;Peter Alexander (ìœ ì‚¬ë„: 0.982)\n",
            "\n",
            "[Anger ê°ì • ì¶”ì²œ ê³¡]\n",
            "  ğŸµ Point Of No Return - Pappenheimer (ìœ ì‚¬ë„: 0.990)\n",
            "  ğŸµ Juggernaut - Smile on the Sinner (ìœ ì‚¬ë„: 0.987)\n",
            "  ğŸµ Blame Myself - ILLENIUM and Virtual Riot Remix - ILLENIUM;Tori Kelly;Virtual Riot (ìœ ì‚¬ë„: 0.986)\n",
            "\n",
            "[Fear ê°ì • ì¶”ì²œ ê³¡]\n",
            "  ğŸµ Amnesia - Gavin Mikhail (ìœ ì‚¬ë„: 0.996)\n",
            "  ğŸµ Atlantis (Sped Up) - fenekot (ìœ ì‚¬ë„: 0.987)\n",
            "  ğŸµ é›£ç ´èˆ¹ - Akina Nakamori (ìœ ì‚¬ë„: 0.986)\n",
            "\n",
            "[Disgust ê°ì • ì¶”ì²œ ê³¡]\n",
            "  ğŸµ Cordeiro e LeÃ£o - Ao Vivo - Central 3;PevÃª Brito;Drops INA (ìœ ì‚¬ë„: 0.985)\n",
            "  ğŸµ Tere Bin - Raghav Chaitanya (ìœ ì‚¬ë„: 0.983)\n",
            "  ğŸµ Someday At Christmas - Stevie Wonder (ìœ ì‚¬ë„: 0.978)\n",
            "\n",
            "[Anxiety ê°ì • ì¶”ì²œ ê³¡]\n",
            "  ğŸµ Bem Simples - Ao Vivo - Roupa Nova;Ed Motta (ìœ ì‚¬ë„: 0.992)\n",
            "  ğŸµ Let in the Light - Moderat (ìœ ì‚¬ë„: 0.982)\n",
            "  ğŸµ 500 PS - CRO (ìœ ì‚¬ë„: 0.982)\n",
            "\n",
            "[Envy ê°ì • ì¶”ì²œ ê³¡]\n",
            "  ğŸµ That Ole Devil Called Love - Remastered - Alison Moyet (ìœ ì‚¬ë„: 0.981)\n",
            "  ğŸµ The Winds of Winter - Ramin Djawadi (ìœ ì‚¬ë„: 0.981)\n",
            "  ğŸµ Spoiled - Joss Stone (ìœ ì‚¬ë„: 0.980)\n",
            "\n",
            "[Embarrassment ê°ì • ì¶”ì²œ ê³¡]\n",
            "  ğŸµ Quiero Verte Una Vez MÃ¡s - Remasterizado - Jorge FalcÃ³n (ìœ ì‚¬ë„: 0.984)\n",
            "  ğŸµ Solamento - Tuyo (ìœ ì‚¬ë„: 0.982)\n",
            "  ğŸµ Swing Low, Sweet Chariot - George Jones (ìœ ì‚¬ë„: 0.982)\n",
            "\n",
            "[Ennui ê°ì • ì¶”ì²œ ê³¡]\n",
            "  ğŸµ Remembering (feat. Tate McRae) - Yutaka Yamada (ìœ ì‚¬ë„: 0.986)\n",
            "  ğŸµ æ°¸ä¸æ£„çµ•çš„æƒ…æ›¸ - å·«å•Ÿè³¢ (ìœ ì‚¬ë„: 0.984)\n",
            "  ğŸµ I Will Rise - Chris Tomlin (ìœ ì‚¬ë„: 0.979)\n",
            "\n",
            "ğŸ‰ ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# In[9]:\n",
        "class ModelManager:\n",
        "    \"\"\"ëª¨ë¸ ì €ì¥/ë¡œë“œ ê´€ë¦¬ í´ë˜ìŠ¤\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def save_model(self, model, preprocessor, emotion_config, file_path):\n",
        "        \"\"\"ëª¨ë¸ ë° ì „ì²˜ë¦¬ê¸° ì €ì¥\"\"\"\n",
        "        try:\n",
        "            # ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "            \n",
        "            save_data = {\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'scaler': preprocessor.scaler,\n",
        "                'label_encoder': preprocessor.label_encoder,\n",
        "                'imputation_means': preprocessor.imputation_means,\n",
        "                'common_features': preprocessor.common_features,\n",
        "                'emotions_config': emotion_config.emotions,\n",
        "                'korean_emotion_map': emotion_config.korean_emotion_map,\n",
        "                'input_dim': len(preprocessor.common_features) if preprocessor.common_features else 0,\n",
        "                'num_classes': len(preprocessor.label_encoder.classes_) if hasattr(preprocessor.label_encoder, 'classes_') else 0\n",
        "            }\n",
        "            \n",
        "            torch.save(save_data, file_path)\n",
        "            print(f\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {file_path}\")\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def load_model(self, file_path, device):\n",
        "        \"\"\"ëª¨ë¸ ë° ì „ì²˜ë¦¬ê¸° ë¡œë“œ\"\"\"\n",
        "        try:\n",
        "            if not os.path.exists(file_path):\n",
        "                print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
        "                return None, None, None\n",
        "            \n",
        "            checkpoint = torch.load(file_path, map_location=device, weights_only=False)\n",
        "            \n",
        "            # ëª¨ë¸ ì¬ìƒì„±\n",
        "            input_dim = checkpoint['input_dim']\n",
        "            num_classes = checkpoint['num_classes']\n",
        "            \n",
        "            model = MusicEmotionClassifier(\n",
        "                input_dim=input_dim,\n",
        "                num_classes=num_classes\n",
        "            ).to(device)\n",
        "            \n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            model.eval()\n",
        "            \n",
        "            # ì „ì²˜ë¦¬ê¸° ë³µì›\n",
        "            preprocessor_restored = DataPreprocessor()\n",
        "            preprocessor_restored.scaler = checkpoint['scaler']\n",
        "            preprocessor_restored.label_encoder = checkpoint['label_encoder']\n",
        "            preprocessor_restored.imputation_means = checkpoint['imputation_means']\n",
        "            preprocessor_restored.common_features = checkpoint['common_features']\n",
        "            \n",
        "            # ê°ì • ì„¤ì • ë³µì›\n",
        "            emotion_config_restored = EmotionConfig()\n",
        "            if 'emotions_config' in checkpoint:\n",
        "                emotion_config_restored.emotions = checkpoint['emotions_config']\n",
        "            if 'korean_emotion_map' in checkpoint:\n",
        "                emotion_config_restored.korean_emotion_map = checkpoint['korean_emotion_map']\n",
        "            \n",
        "            print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {file_path}\")\n",
        "            return model, preprocessor_restored, emotion_config_restored\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "            return None, None, None\n",
        "\n",
        "# ëª¨ë¸ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
        "model_manager = ModelManager()\n",
        "\n",
        "# ëª¨ë¸ ì €ì¥ (í•™ìŠµëœ ëª¨ë¸ì´ ìˆì„ ë•Œ)\n",
        "MODEL_SAVE_PATH = \"models/emotion_classifier.pth\"\n",
        "\n",
        "if hasattr(trainer, 'model') and trainer.model is not None:\n",
        "    success = model_manager.save_model(\n",
        "        trainer.model, preprocessor, emotion_config, MODEL_SAVE_PATH\n",
        "    )\n",
        "    if success:\n",
        "        print(f\"ğŸ’¾ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {MODEL_SAVE_PATH}\")\n",
        "else:\n",
        "    print(\"âš ï¸ ì €ì¥í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•´ì£¼ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zog-1RxBYz_",
        "outputId": "8c5f8497-8ca6-4607-d836-c32ae204d6dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”® ê°ì • ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸\n",
            "==============================\n",
            "\n",
            "1. ê¸°ìœ ìŒì•… íŠ¹ì„±ìœ¼ë¡œ ì˜ˆì¸¡:\n",
            "ì˜ˆì¸¡ ê°ì •: Joy\n",
            "ì‹ ë¢°ë„: 1.000\n",
            "\n",
            "2. ìŠ¬í”ˆ ìŒì•… íŠ¹ì„±ìœ¼ë¡œ ì˜ˆì¸¡:\n",
            "ì˜ˆì¸¡ ê°ì •: Sadness\n",
            "ì‹ ë¢°ë„: 0.910\n",
            "\n",
            "3. ê°€ì‚¬ë¡œ ê°ì • ì˜ˆì¸¡:\n",
            "ì˜ˆì¸¡ ê°ì •: Joy\n",
            "ì‹ ë¢°ë„: 0.419\n",
            "\n",
            "âœ¨ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# ## 10. ìŒì•… ì¶”ì²œ ì‹œìŠ¤í…œ\n",
        "\n",
        "# In[10]:\n",
        "class MusicRecommendationSystem:\n",
        "    \"\"\"ìŒì•… ì¶”ì²œ ì‹œìŠ¤í…œ\"\"\"\n",
        "    \n",
        "    def __init__(self, model, preprocessor, emotion_config, device):\n",
        "        self.model = model\n",
        "        self.preprocessor = preprocessor\n",
        "        self.emotion_config = emotion_config\n",
        "        self.device = device\n",
        "    \n",
        "    def recommend_by_valence(self, emotion, n, data_df):\n",
        "        \"\"\"Valence ê¸°ë°˜ ì¶”ì²œ\"\"\"\n",
        "        if emotion not in self.emotion_config.emotions:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        valence_range = self.emotion_config.emotions[emotion]['valence']\n",
        "        vmin, vmax = valence_range\n",
        "        \n",
        "        filtered_df = data_df[\n",
        "            (data_df['valence'] >= vmin) & (data_df['valence'] < vmax)\n",
        "        ]\n",
        "        \n",
        "        if len(filtered_df) == 0:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        return filtered_df.sample(n=min(n, len(filtered_df)))\n",
        "    \n",
        "    def recommend_by_similarity(self, emotion, n, data_df, train_df):\n",
        "        \"\"\"ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ\"\"\"\n",
        "        features = self.preprocessor.get_feature_names()\n",
        "        if not features:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        # ë°ì´í„° ì „ì²˜ë¦¬\n",
        "        df_features = data_df[features].fillna(self.preprocessor.imputation_means)\n",
        "        df_features = df_features.replace([np.inf, -np.inf], self.preprocessor.imputation_means.mean())\n",
        "        \n",
        "        # ìŠ¤ì¼€ì¼ë§\n",
        "        scaled_features = self.preprocessor.scaler.transform(df_features.values)\n",
        "        \n",
        "        # ê°ì • í”„ë¡œí•„ ê³„ì‚°\n",
        "        emotion_data = train_df[train_df['emotion_cat'] == emotion]\n",
        "        if emotion_data.empty:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        profile_raw = emotion_data[features].mean()\n",
        "        profile_filled = profile_raw.fillna(self.preprocessor.imputation_means)\n",
        "        profile_scaled = self.preprocessor.scaler.transform(profile_filled.values.reshape(1, -1))\n",
        "        \n",
        "        # ìœ ì‚¬ë„ ê³„ì‚°\n",
        "        similarities = cosine_similarity(profile_scaled, scaled_features)[0]\n",
        "        \n",
        "        # ê²°ê³¼ ì •ë ¬\n",
        "        data_df_copy = data_df.copy()\n",
        "        data_df_copy['similarity'] = similarities\n",
        "        \n",
        "        return data_df_copy.nlargest(n, 'similarity')\n",
        "    \n",
        "    def recommend_by_neural_network(self, emotion, n, data_df):\n",
        "        \"\"\"ì‹ ê²½ë§ ê¸°ë°˜ ì¶”ì²œ\"\"\"\n",
        "        features = self.preprocessor.get_feature_names()\n",
        "        if not features:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        # ë°ì´í„° ì „ì²˜ë¦¬\n",
        "        df_features = data_df[features].fillna(self.preprocessor.imputation_means)\n",
        "        df_features = df_features.replace([np.inf, -np.inf], self.preprocessor.imputation_means.mean())\n",
        "        \n",
        "        # ìŠ¤ì¼€ì¼ë§\n",
        "        scaled_features = self.preprocessor.scaler.transform(df_features.values)\n",
        "        \n",
        "        # ì˜ˆì¸¡\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            features_tensor = torch.FloatTensor(scaled_features).to(self.device)\n",
        "            probabilities = self.model(features_tensor).cpu().numpy()\n",
        "        \n",
        "        # ê°ì • ì¸ë±ìŠ¤ ì°¾ê¸°\n",
        "        try:\n",
        "            emotion_idx = self.preprocessor.label_encoder.transform([emotion])[0]\n",
        "        except ValueError:\n",
        "            emotion_idx = 0\n",
        "        \n",
        "        # ê²°ê³¼ ì •ë ¬\n",
        "        data_df_copy = data_df.copy()\n",
        "        data_df_copy['probability'] = probabilities[:, emotion_idx]\n",
        "        \n",
        "        return data_df_copy.nlargest(n, 'probability')\n",
        "    \n",
        "    def recommend_hybrid(self, target_emotion, n, data_df, train_df=None):\n",
        "        \"\"\"í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ (ì—¬ëŸ¬ ë°©ë²• ê²°í•©)\"\"\"\n",
        "        recommendations = []\n",
        "        fetch_count = max(n * 2, 10)  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ ì¤‘ë³µ ì œê±°\n",
        "        \n",
        "        methods = [\n",
        "            ('valence', lambda: self.recommend_by_valence(target_emotion, fetch_count, data_df)),\n",
        "            ('neural', lambda: self.recommend_by_neural_network(target_emotion, fetch_count, data_df))\n",
        "        ]\n",
        "        \n",
        "        # ìœ ì‚¬ë„ ë°©ë²•ì€ í•™ìŠµ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ\n",
        "        if train_df is not None:\n",
        "            methods.append(\n",
        "                ('similarity', lambda: self.recommend_by_similarity(target_emotion, fetch_count, data_df, train_df))\n",
        "            )\n",
        "        \n",
        "        for method_name, method_func in methods:\n",
        "            try:\n",
        "                result = method_func()\n",
        "                if not result.empty:\n",
        "                    recommendations.append(result)\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ {method_name} ë°©ë²• ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
        "        \n",
        "        if not recommendations:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        # ê²°í•© ë° ì¤‘ë³µ ì œê±°\n",
        "        combined = pd.concat(recommendations, ignore_index=True)\n",
        "        \n",
        "        # track_nameê³¼ track_artistê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¤‘ë³µ ì œê±°\n",
        "        if 'track_name' in combined.columns and 'track_artist' in combined.columns:\n",
        "            return combined.drop_duplicates(subset=['track_name', 'track_artist']).head(n)\n",
        "        else:\n",
        "            return combined.drop_duplicates().head(n)\n",
        "    \n",
        "    def get_emotion_from_korean(self, korean_text):\n",
        "        \"\"\"í•œêµ­ì–´ í…ìŠ¤íŠ¸ì—ì„œ ê°ì • ì¶”ì¶œ\"\"\"\n",
        "        emotion, keyword = self.emotion_config.map_korean_emotion(korean_text)\n",
        "        if emotion:\n",
        "            emotion_label = self.emotion_config.get_emotion_label(emotion)\n",
        "            print(f\"'{korean_text}'ì—ì„œ '{keyword}' í‚¤ì›Œë“œë¡œ '{emotion_label}' ê°ì •ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤.\")\n",
        "            return emotion\n",
        "        else:\n",
        "            print(f\"'{korean_text}'ì—ì„œ ê°ì •ì„ ê°ì§€í•  ìˆ˜ ì—†ì–´ 'í‰ì˜¨' ê°ì •ìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.\")\n",
        "            return 'calm'\n",
        "\n",
        "print(\"âœ… ìŒì•… ì¶”ì²œ ì‹œìŠ¤í…œ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "brlT1jj_BbHY",
        "outputId": "b41fb74f-8fbd-49b4-d7d8-6c2d3fd26b09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ’¾ ê²°ê³¼ ì €ì¥...\n",
            "âœ… ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ!\n",
            "- processed_train_data.csv: ì²˜ë¦¬ëœ í›ˆë ¨ ë°ì´í„°\n",
            "- processed_test_data.csv: ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
            "- emotion_recommendations.csv: ê°ì •ë³„ ì¶”ì²œ ê³¡\n",
            "\n",
            "ğŸ“¥ ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ:\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f609de2c-9ef6-4af9-9ead-977256bff8d9\", \"processed_train_data.csv\", 8298209)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_ebeb518d-a1ab-45dc-9c22-f3118915fd43\", \"emotion_recommendations.csv\", 11828)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# In[11]:\n",
        "class EmotionPredictor:\n",
        "    \"\"\"ê°ì • ì˜ˆì¸¡ ì‹œìŠ¤í…œ\"\"\"\n",
        "    \n",
        "    def __init__(self, model, preprocessor, emotion_config, device):\n",
        "        self.model = model\n",
        "        self.preprocessor = preprocessor\n",
        "        self.emotion_config = emotion_config\n",
        "        self.device = device\n",
        "    \n",
        "    def predict_emotion(self, audio_features):\n",
        "        \"\"\"ìŒí–¥ íŠ¹ì„±ìœ¼ë¡œë¶€í„° ê°ì • ì˜ˆì¸¡\"\"\"\n",
        "        features = self.preprocessor.get_feature_names()\n",
        "        \n",
        "        if len(audio_features) != len(features):\n",
        "            print(f\"âŒ ì…ë ¥ íŠ¹ì„± ìˆ˜ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆìƒ: {len(features)}, ì…ë ¥: {len(audio_features)}\")\n",
        "            return None, None, None\n",
        "        \n",
        "        # íŠ¹ì„± ì „ì²˜ë¦¬\n",
        "        features_series = pd.Series(audio_features, index=features)\n",
        "        features_series = features_series.replace([np.inf, -np.inf], np.nan)\n",
        "        \n",
        "        # ê²°ì¸¡ê°’ ì²˜ë¦¬\n",
        "        features_filled = features_series.fillna(self.preprocessor.imputation_means)\n",
        "        \n",
        "        # ìŠ¤ì¼€ì¼ë§\n",
        "        features_scaled = self.preprocessor.scaler.transform(features_filled.values.reshape(1, -1))\n",
        "        \n",
        "        # ì˜ˆì¸¡\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            features_tensor = torch.FloatTensor(features_scaled).to(self.device)\n",
        "            probabilities = self.model(features_tensor).cpu().numpy()[0]\n",
        "        \n",
        "        # ìµœê³  í™•ë¥  ê°ì •\n",
        "        predicted_idx = probabilities.argmax()\n",
        "        predicted_emotion = self.preprocessor.label_encoder.inverse_transform([predicted_idx])[0]\n",
        "        confidence = probabilities[predicted_idx]\n",
        "        \n",
        "        # ì „ì²´ í™•ë¥  ë¶„í¬\n",
        "        emotion_classes = self.preprocessor.get_emotion_classes()\n",
        "        emotion_labels = [self.emotion_config.get_emotion_label(e) for e in emotion_classes]\n",
        "        \n",
        "        probability_distribution = {\n",
        "            emotion_labels[i]: prob for i, prob in enumerate(probabilities)\n",
        "        }\n",
        "        \n",
        "        return predicted_emotion, confidence, probability_distribution\n",
        "    \n",
        "    def analyze_playlist(self, track_names, data_df):\n",
        "        \"\"\"í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ê°ì • ë¶„ì„\"\"\"\n",
        "        if 'track_name' not in data_df.columns:\n",
        "            print(\"âŒ íŠ¸ë™ëª… ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            return None, None\n",
        "        \n",
        "        # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ íŠ¸ë™ ì°¾ê¸°\n",
        "        playlist_tracks = data_df[data_df['track_name'].isin(track_names)]\n",
        "        \n",
        "        if playlist_tracks.empty:\n",
        "            print(\"âŒ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì˜ íŠ¸ë™ì„ ë°ì´í„°ì…‹ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            return None, None\n",
        "        \n",
        "        print(f\"ğŸ“Š í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì—ì„œ {len(playlist_tracks)} íŠ¸ë™ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        \n",
        "        # í‰ê·  Valence ê³„ì‚°\n",
        "        avg_valence = playlist_tracks['valence'].mean() if 'valence' in playlist_tracks.columns else 0\n",
        "        \n",
        "        # ê°€ì¥ ë¹ˆë²ˆí•œ ê°ì •\n",
        "        if 'emotion_cat' in playlist_tracks.columns:\n",
        "            emotion_counts = playlist_tracks['emotion_cat'].value_counts()\n",
        "            most_common_emotion = emotion_counts.index[0]\n",
        "            emotion_label = self.emotion_config.get_emotion_label(most_common_emotion)\n",
        "        else:\n",
        "            emotion_label = 'ì•Œ ìˆ˜ ì—†ìŒ'\n",
        "        \n",
        "        return emotion_label, avg_valence\n",
        "\n",
        "print(\"âœ… ê°ì • ì˜ˆì¸¡ ì‹œìŠ¤í…œ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLkcXhSzCDjn"
      },
      "outputs": [],
      "source": [
        "# ## 12. ì‹œìŠ¤í…œ í†µí•© ë° ì‚¬ìš© ì˜ˆì‹œ\n",
        "\n",
        "# In[12]:\n",
        "# ì‹œìŠ¤í…œ í†µí•© í´ë˜ìŠ¤\n",
        "class IntegratedMusicSystem:\n",
        "    \"\"\"í†µí•© ìŒì•… ê°ì • ì‹œìŠ¤í…œ\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.preprocessor = None\n",
        "        self.emotion_config = None\n",
        "        self.recommendation_system = None\n",
        "        self.emotion_predictor = None\n",
        "        self.data_loader = None\n",
        "        self.device = device\n",
        "    \n",
        "    def initialize_from_trained_components(self, model, preprocessor, emotion_config, data_loader):\n",
        "        \"\"\"í•™ìŠµëœ ì»´í¬ë„ŒíŠ¸ë¡œ ì´ˆê¸°í™”\"\"\"\n",
        "        self.model = model\n",
        "        self.preprocessor = preprocessor\n",
        "        self.emotion_config = emotion_config\n",
        "        self.data_loader = data_loader\n",
        "        \n",
        "        self.recommendation_system = MusicRecommendationSystem(\n",
        "            model, preprocessor, emotion_config, self.device\n",
        "        )\n",
        "        self.emotion_predictor = EmotionPredictor(\n",
        "            model, preprocessor, emotion_config, self.device\n",
        "        )\n",
        "        \n",
        "        print(\"âœ… í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "    \n",
        "    def load_from_saved_model(self, model_path):\n",
        "        \"\"\"ì €ì¥ëœ ëª¨ë¸ì—ì„œ ë¡œë“œ\"\"\"\n",
        "        model_manager = ModelManager()\n",
        "        model, preprocessor, emotion_config = model_manager.load_model(model_path, self.device)\n",
        "        \n",
        "        if model is not None:\n",
        "            self.model = model\n",
        "            self.preprocessor = preprocessor\n",
        "            self.emotion_config = emotion_config\n",
        "            \n",
        "            self.recommendation_system = MusicRecommendationSystem(\n",
        "                model, preprocessor, emotion_config, self.device\n",
        "            )\n",
        "            self.emotion_predictor = EmotionPredictor(\n",
        "                model, preprocessor, emotion_config, self.device\n",
        "            )\n",
        "            \n",
        "            print(\"âœ… ì €ì¥ëœ ëª¨ë¸ì—ì„œ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨\")\n",
        "            return False\n",
        "    \n",
        "    def recommend_music(self, emotion_text, n=5, method='hybrid', data_source='test'):\n",
        "        \"\"\"ìŒì•… ì¶”ì²œ\"\"\"\n",
        "        if not self.recommendation_system:\n",
        "            print(\"âŒ ì¶”ì²œ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        # ê°ì • ë§¤í•‘\n",
        "        target_emotion = self.recommendation_system.get_emotion_from_korean(emotion_text)\n",
        "        \n",
        "        # ë°ì´í„° ì„ íƒ\n",
        "        if data_source == 'test' and hasattr(self.data_loader, 'test_df'):\n",
        "            data_df = self.data_loader.test_df\n",
        "            train_df = self.data_loader.train_df if hasattr(self.data_loader, 'train_df') else None\n",
        "        elif data_source == 'train' and hasattr(self.data_loader, 'train_df'):\n",
        "            data_df = self.data_loader.train_df\n",
        "            train_df = self.data_loader.train_df\n",
        "        else:\n",
        "            print(f\"âŒ {data_source} ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        # ì¶”ì²œ ì‹¤í–‰\n",
        "        if method == 'hybrid':\n",
        "            return self.recommendation_system.recommend_hybrid(target_emotion, n, data_df, train_df)\n",
        "        elif method == 'valence':\n",
        "            return self.recommendation_system.recommend_by_valence(target_emotion, n, data_df)\n",
        "        elif method == 'neural':\n",
        "            return self.recommendation_system.recommend_by_neural_network(target_emotion, n, data_df)\n",
        "        elif method == 'similarity' and train_df is not None:\n",
        "            return self.recommendation_system.recommend_by_similarity(target_emotion, n, data_df, train_df)\n",
        "        else:\n",
        "            print(f\"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¶”ì²œ ë°©ë²•ì…ë‹ˆë‹¤: {method}\")\n",
        "            return pd.DataFrame()\n",
        "    \n",
        "    def predict_music_emotion(self, audio_features):\n",
        "        \"\"\"ìŒì•… ê°ì • ì˜ˆì¸¡\"\"\"\n",
        "        if not self.emotion_predictor:\n",
        "            print(\"âŒ ê°ì • ì˜ˆì¸¡ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "            return None, None, None\n",
        "        \n",
        "        return self.emotion_predictor.predict_emotion(audio_features)\n",
        "    \n",
        "    def analyze_playlist_emotion(self, track_names, data_source='test'):\n",
        "        \"\"\"í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ê°ì • ë¶„ì„\"\"\"\n",
        "        if not self.emotion_predictor:\n",
        "            print(\"âŒ ê°ì • ì˜ˆì¸¡ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "            return None, None\n",
        "        \n",
        "        # ë°ì´í„° ì„ íƒ\n",
        "        if data_source == 'test' and hasattr(self.data_loader, 'test_df'):\n",
        "            data_df = self.data_loader.test_df\n",
        "        elif data_source == 'train' and hasattr(self.data_loader, 'train_df'):\n",
        "            data_df = self.data_loader.train_df\n",
        "        else:\n",
        "            print(f\"âŒ {data_source} ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            return None, None\n",
        "        \n",
        "        return self.emotion_predictor.analyze_playlist(track_names, data_df)\n",
        "    \n",
        "    def get_system_status(self):\n",
        "        \"\"\"ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸\"\"\"\n",
        "        status = {\n",
        "            'ëª¨ë¸ ë¡œë“œë¨': self.model is not None,\n",
        "            'ì „ì²˜ë¦¬ê¸° ì¤€ë¹„ë¨': self.preprocessor is not None,\n",
        "            'ê°ì • ì„¤ì • ë¡œë“œë¨': self.emotion_config is not None,\n",
        "            'ì¶”ì²œ ì‹œìŠ¤í…œ ì¤€ë¹„ë¨': self.recommendation_system is not None,\n",
        "            'ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì¤€ë¹„ë¨': self.emotion_predictor is not None,\n",
        "            'ë°ì´í„° ë¡œë“œë¨': self.data_loader is not None,\n",
        "        }\n",
        "        \n",
        "        return status\n",
        "\n",
        "# í†µí•© ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
        "integrated_system = IntegratedMusicSystem()\n",
        "\n",
        "# í•™ìŠµëœ ì»´í¬ë„ŒíŠ¸ê°€ ìˆë‹¤ë©´ ì´ˆê¸°í™”\n",
        "if all(var in locals() for var in ['trainer', 'preprocessor', 'emotion_config', 'data_loader']):\n",
        "    if hasattr(trainer, 'model') and trainer.model is not None:\n",
        "        integrated_system.initialize_from_trained_components(\n",
        "            trainer.model, preprocessor, emotion_config, data_loader\n",
        "        )\n",
        "    else:\n",
        "        print(\"âš ï¸ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "else:\n",
        "    print(\"âš ï¸ í•„ìš”í•œ ì»´í¬ë„ŒíŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ## 13. ì‚¬ìš© ì˜ˆì‹œ ë° ë°ëª¨\n",
        "\n",
        "# In[13]:\n",
        "def run_recommendation_demo(system):\n",
        "    \"\"\"ì¶”ì²œ ì‹œìŠ¤í…œ ë°ëª¨\"\"\"\n",
        "    print(\"ğŸµ ìŒì•… ì¶”ì²œ ë°ëª¨\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸\n",
        "    status = system.get_system_status()\n",
        "    if not all(status.values()):\n",
        "        print(\"âŒ ì‹œìŠ¤í…œì´ ì™„ì „íˆ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        print(\"ì‹œìŠ¤í…œ ìƒíƒœ:\")\n",
        "        for key, value in status.items():\n",
        "            status_icon = \"âœ…\" if value else \"âŒ\"\n",
        "            print(f\"   {status_icon} {key}\")\n",
        "        return\n",
        "    \n",
        "    # ë‹¤ì–‘í•œ ê°ì •ìœ¼ë¡œ ì¶”ì²œ í…ŒìŠ¤íŠ¸\n",
        "    test_emotions = [\n",
        "        \"ì˜¤ëŠ˜ ì •ë§ ê¸°ìœ í•˜ë£¨ì˜€ì–´!\",\n",
        "        \"ë¹„ ì˜¤ëŠ” ë‚ ì´ë¼ ìš°ìš¸í•´\",\n",
        "        \"ì‹œí—˜ ë•Œë¬¸ì— ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„\",\n",
        "        \"ì§‘ì—ì„œ í¸ì•ˆí•˜ê²Œ ì‰¬ê³  ì‹¶ì–´\"\n",
        "    ]\n",
        "    \n",
        "    for emotion_text in test_emotions:\n",
        "        print(f\"\\nğŸ¯ ê°ì •: '{emotion_text}'\")\n",
        "        \n",
        "        recommendations = system.recommend_music(emotion_text, n=3, method='hybrid')\n",
        "        \n",
        "        if not recommendations.empty:\n",
        "            print(\"ğŸ“€ ì¶”ì²œ ê³¡ëª©:\")\n",
        "            display_columns = []\n",
        "            \n",
        "            if 'track_name' in recommendations.columns:\n",
        "                display_columns.append('track_name')\n",
        "            if 'track_artist' in recommendations.columns:\n",
        "                display_columns.append('track_artist')\n",
        "            if 'valence' in recommendations.columns:\n",
        "                display_columns.append('valence')\n",
        "            if 'emotion_cat' in recommendations.columns:\n",
        "                display_columns.append('emotion_cat')\n",
        "            \n",
        "            if display_columns:\n",
        "                for idx, row in recommendations[display_columns].head(3).iterrows():\n",
        "                    track_info = []\n",
        "                    if 'track_name' in row:\n",
        "                        track_info.append(f\"ğŸµ {row['track_name']}\")\n",
        "                    if 'track_artist' in row:\n",
        "                        track_info.append(f\"- {row['track_artist']}\")\n",
        "                    if 'valence' in row:\n",
        "                        track_info.append(f\"(valence: {row['valence']:.3f})\")\n",
        "                    \n",
        "                    print(f\"   {' '.join(track_info)}\")\n",
        "            else:\n",
        "                print(\"   ê³¡ ì •ë³´ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        else:\n",
        "            print(\"   âŒ ì¶”ì²œê³¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        \n",
        "        print(\"-\" * 40)\n",
        "\n",
        "def run_prediction_demo(system):\n",
        "    \"\"\"ê°ì • ì˜ˆì¸¡ ë°ëª¨\"\"\"\n",
        "    print(\"ğŸ­ ê°ì • ì˜ˆì¸¡ ë°ëª¨\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸\n",
        "    status = system.get_system_status()\n",
        "    if not status['ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì¤€ë¹„ë¨']:\n",
        "        print(\"âŒ ì˜ˆì¸¡ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "    \n",
        "    # ìƒ˜í”Œ ìŒí–¥ íŠ¹ì„±ë“¤\n",
        "    sample_tracks = [\n",
        "        {\n",
        "            'name': 'ë°ê³  ê²½ì¾Œí•œ íŒì†¡',\n",
        "            'features': [0.85, 0.78, 0.82, 0.15, 0.02, 0.25, 0.08, -4.5, 125.0]\n",
        "        },\n",
        "        {\n",
        "            'name': 'ê°ì„±ì ì¸ ë°œë¼ë“œ',\n",
        "            'features': [0.15, 0.25, 0.35, 0.85, 0.05, 0.12, 0.04, -12.0, 65.0]\n",
        "        },\n",
        "        {\n",
        "            'name': 'ê²©ë ¬í•œ ë¡ ìŒì•…',\n",
        "            'features': [0.25, 0.92, 0.65, 0.08, 0.01, 0.35, 0.15, -2.8, 145.0]\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    feature_names = system.preprocessor.get_feature_names()\n",
        "    print(f\"ğŸ” ì‚¬ìš© íŠ¹ì„±: {feature_names}\")\n",
        "    print()\n",
        "    \n",
        "    for track in sample_tracks:\n",
        "        print(f\"ğŸ¼ {track['name']}\")\n",
        "        \n",
        "        emotion, confidence, distribution = system.predict_music_emotion(track['features'])\n",
        "        \n",
        "        if emotion:\n",
        "            emotion_label = system.emotion_config.get_emotion_label(emotion)\n",
        "            print(f\"   ğŸ­ ì˜ˆì¸¡ ê°ì •: {emotion_label} (ì‹ ë¢°ë„: {confidence:.3f})\")\n",
        "            \n",
        "            # ìƒìœ„ 3ê°œ ê°ì • í™•ë¥ \n",
        "            sorted_emotions = sorted(distribution.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "            print(\"   ğŸ“Š ìƒìœ„ 3ê°œ ê°ì •:\")\n",
        "            for i, (emotion_name, prob) in enumerate(sorted_emotions, 1):\n",
        "                bar = \"â–ˆ\" * int(prob * 15)\n",
        "                print(f\"      {i}. {emotion_name}: {prob:.3f} {bar}\")\n",
        "        else:\n",
        "            print(\"   âŒ ê°ì • ì˜ˆì¸¡ ì‹¤íŒ¨\")\n",
        "        \n",
        "        print(\"-\" * 50)\n",
        "\n",
        "# ë°ëª¨ ì‹¤í–‰\n",
        "print(\"ğŸš€ í†µí•© ì‹œìŠ¤í…œ ë°ëª¨ ì‹¤í–‰\")\n",
        "\n",
        "if integrated_system.get_system_status()['ëª¨ë¸ ë¡œë“œë¨']:\n",
        "    run_recommendation_demo(integrated_system)\n",
        "    run_prediction_demo(integrated_system)\n",
        "else:\n",
        "    print(\"âš ï¸ ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•˜ê±°ë‚˜ ì €ì¥ëœ ëª¨ë¸ì„ ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ## 14. ë°ì´í„° ì‹œê°í™”\n",
        "\n",
        "# In[14]:\n",
        "def plot_emotion_distribution(data_df, emotion_config, title=\"ê°ì • ë¶„í¬\"):\n",
        "    \"\"\"ê°ì • ë¶„í¬ ì‹œê°í™”\"\"\"\n",
        "    if 'emotion_cat' not in data_df.columns:\n",
        "        print(\"âŒ emotion_cat ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "    \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    # ê°ì • ë¶„í¬ ê³„ì‚°\n",
        "    emotion_counts = data_df['emotion_cat'].value_counts()\n",
        "    \n",
        "    # í•œêµ­ì–´ ë ˆì´ë¸”ë¡œ ë³€í™˜\n",
        "    korean_labels = [emotion_config.get_emotion_label(emotion) for emotion in emotion_counts.index]\n",
        "    \n",
        "    # ë§‰ëŒ€ ê·¸ë˜í”„\n",
        "    plt.subplot(1, 2, 1)\n",
        "    bars = plt.bar(korean_labels, emotion_counts.values, color=plt.cm.Set3(np.arange(len(korean_labels))))\n",
        "    plt.title(f'{title} - ê³¡ ìˆ˜')\n",
        "    plt.xlabel('ê°ì •')\n",
        "    plt.ylabel('ê³¡ ìˆ˜')\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    # ê°’ í‘œì‹œ\n",
        "    for bar, count in zip(bars, emotion_counts.values):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(emotion_counts.values)*0.01,\n",
        "                f'{count:,}', ha='center', va='bottom')\n",
        "    \n",
        "    # íŒŒì´ ì°¨íŠ¸\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.pie(emotion_counts.values, labels=korean_labels, autopct='%1.1f%%', \n",
        "            colors=plt.cm.Set3(np.arange(len(korean_labels))))\n",
        "    plt.title(f'{title} - ë¹„ìœ¨')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_valence_energy_scatter(data_df, emotion_config, title=\"Valence-Energy ë¶„í¬\"):\n",
        "    \"\"\"Valence-Energy ì‚°ì ë„\"\"\"\n",
        "    if not all(col in data_df.columns for col in ['valence', 'energy', 'emotion_cat']):\n",
        "        print(\"âŒ í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "    \n",
        "    plt.figure(figsize=(12, 8))\n",
        "    \n",
        "    # ê°ì •ë³„ë¡œ ë‹¤ë¥¸ ìƒ‰ìƒ\n",
        "    emotions = data_df['emotion_cat'].unique()\n",
        "    colors = plt.cm.Set3(np.linspace(0, 1, len(emotions)))\n",
        "    \n",
        "    for emotion, color in zip(emotions, colors):\n",
        "        emotion_data = data_df[data_df['emotion_cat'] == emotion]\n",
        "        label = emotion_config.get_emotion_label(emotion)\n",
        "        \n",
        "        plt.scatter(emotion_data['valence'], emotion_data['energy'], \n",
        "                   alpha=0.6, c=[color], label=label, s=30)\n",
        "    \n",
        "    plt.xlabel('Valence (ê¸ì •ì„±)', fontsize=12)\n",
        "    plt.ylabel('Energy (ì—ë„ˆì§€)', fontsize=12)\n",
        "    plt.title(title, fontsize=14, fontweight='bold')\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ì‹œê°í™” ì‹¤í–‰\n",
        "if hasattr(data_loader, 'train_df') and data_loader.train_df is not None:\n",
        "    print(\"ğŸ“Š í•™ìŠµ ë°ì´í„° ì‹œê°í™”\")\n",
        "    plot_emotion_distribution(data_loader.train_df, emotion_config, \"í•™ìŠµ ë°ì´í„° ê°ì • ë¶„í¬\")\n",
        "    plot_valence_energy_scatter(data_loader.train_df, emotion_config, \"í•™ìŠµ ë°ì´í„° Valence-Energy ë¶„í¬\")\n",
        "\n",
        "if hasattr(data_loader, 'test_df') and data_loader.test_df is not None:\n",
        "    print(\"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‹œê°í™”\")\n",
        "    plot_emotion_distribution(data_loader.test_df, emotion_config, \"í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°ì • ë¶„í¬\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ## 15. ì‹œìŠ¤í…œ ìƒíƒœ ì ê²€ ë° ë¬¸ì œ í•´ê²°\n",
        "\n",
        "# In[15]:\n",
        "def comprehensive_system_check():\n",
        "    \"\"\"ì¢…í•© ì‹œìŠ¤í…œ ì ê²€\"\"\"\n",
        "    print(\"ğŸ”§ ì¢…í•© ì‹œìŠ¤í…œ ìƒíƒœ ì ê²€\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # 1. ë°ì´í„° ë¡œë“œ ìƒíƒœ\n",
        "    print(\"ğŸ“Š 1. ë°ì´í„° ìƒíƒœ\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    train_status = hasattr(data_loader, 'train_df') and data_loader.train_df is not None\n",
        "    test_status = hasattr(data_loader, 'test_df') and data_loader.test_df is not None\n",
        "    \n",
        "    if train_status:\n",
        "        print(f\"âœ… í•™ìŠµ ë°ì´í„°: {len(data_loader.train_df):,} íŠ¸ë™\")\n",
        "        print(f\"   ì»¬ëŸ¼: {list(data_loader.train_df.columns)}\")\n",
        "    else:\n",
        "        print(\"âŒ í•™ìŠµ ë°ì´í„° ì—†ìŒ\")\n",
        "        print(\"   í•´ê²°ë°©ë²•: data_loader.load_train_data('ê²½ë¡œ') ì‹¤í–‰\")\n",
        "    \n",
        "    if test_status:\n",
        "        print(f\"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(data_loader.test_df):,} íŠ¸ë™\")\n",
        "        print(f\"   ì»¬ëŸ¼: {list(data_loader.test_df.columns)}\")\n",
        "    else:\n",
        "        print(\"âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì—†ìŒ\")\n",
        "        print(\"   í•´ê²°ë°©ë²•: data_loader.load_test_data('ê²½ë¡œ') ì‹¤í–‰\")\n",
        "    \n",
        "    # 2. ëª¨ë¸ ìƒíƒœ\n",
        "    print(f\"\\nğŸ¤– 2. ëª¨ë¸ ìƒíƒœ\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    model_status = hasattr(trainer, 'model') and trainer.model is not None\n",
        "    if model_status:\n",
        "        print(\"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ\")\n",
        "        if hasattr(preprocessor, 'common_features'):\n",
        "            print(f\"   ì…ë ¥ íŠ¹ì„±: {len(preprocessor.common_features)}ê°œ\")\n",
        "            print(f\"   ê°ì • í´ë˜ìŠ¤: {len(preprocessor.get_emotion_classes())}ê°œ\")\n",
        "    else:\n",
        "        print(\"âŒ ëª¨ë¸ ë¯¸í•™ìŠµ\")\n",
        "        print(\"   í•´ê²°ë°©ë²•: trainer.train_model() ì‹¤í–‰\")\n",
        "    \n",
        "    # 3. í†µí•© ì‹œìŠ¤í…œ ìƒíƒœ\n",
        "    print(f\"\\nğŸµ 3. í†µí•© ì‹œìŠ¤í…œ ìƒíƒœ\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    if 'integrated_system' in locals():\n",
        "        system_status = integrated_system.get_system_status()\n",
        "        for component, status in system_status.items():\n",
        "            icon = \"âœ…\" if status else \"âŒ\"\n",
        "            print(f\"   {icon} {component}\")\n",
        "    else:\n",
        "        print(\"âŒ í†µí•© ì‹œìŠ¤í…œ ë¯¸ì´ˆê¸°í™”\")\n",
        "    \n",
        "    # 4. ê¶Œì¥ ì‚¬í•­\n",
        "    print(f\"\\nğŸ’¡ 4. ê¶Œì¥ ì‚¬í•­\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    recommendations = []\n",
        "    \n",
        "    if not train_status or not test_status:\n",
        "        recommendations.append(\"ë°ì´í„° íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ê³  ì˜¬ë°”ë¥¸ ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ì„¸ìš”\")\n",
        "    \n",
        "    if not model_status:\n",
        "        recommendations.append(\"ëª¨ë¸ì„ í•™ìŠµí•˜ê±°ë‚˜ ê¸°ì¡´ ì €ì¥ëœ ëª¨ë¸ì„ ë¡œë“œí•˜ì„¸ìš”\")\n",
        "    \n",
        "    if train_status and test_status and model_status:\n",
        "        recommendations.append(\"ëª¨ë“  ì‹œìŠ¤í…œì´ ì •ìƒì…ë‹ˆë‹¤! ì¶”ì²œ ë° ì˜ˆì¸¡ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
        "    \n",
        "    for i, rec in enumerate(recommendations, 1):\n",
        "        print(f\"   {i}. {rec}\")\n",
        "    \n",
        "    # 5. ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ\n",
        "    print(f\"\\nğŸš€ 5. ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ\")\n",
        "    print(\"-\" * 30)\n",
        "    print(\"1. ë°ì´í„° ë¡œë“œ:\")\n",
        "    print(\"   data_loader.load_train_data('ê²½ë¡œ/spotify_tracks_dataset.csv')\")\n",
        "    print(\"   data_loader.load_test_data('ê²½ë¡œ/Spotify_Youtube.csv')\")\n",
        "    print()\n",
        "    print(\"2. ë°ì´í„° ì „ì²˜ë¦¬:\")\n",
        "    print(\"   X_train, y_train, X_test, y_test = preprocessor.prepare_data(...)\")\n",
        "    print()\n",
        "    print(\"3. ëª¨ë¸ í•™ìŠµ:\")\n",
        "    print(\"   model = trainer.train_model(X_train, y_train, X_test, y_test)\")\n",
        "    print()\n",
        "    print(\"4. ì‹œìŠ¤í…œ ì‚¬ìš©:\")\n",
        "    print(\"   integrated_system.recommend_music('ê¸°ìœ ê¸°ë¶„ì´ì•¼!', n=5)\")\n",
        "    print(\"   integrated_system.predict_music_emotion([0.8, 0.7, ...])\")\n",
        "\n",
        "# ì‹œìŠ¤í…œ ì ê²€ ì‹¤í–‰\n",
        "comprehensive_system_check()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ## 16. ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ë“¤\n",
        "\n",
        "# In[16]:\n",
        "def quick_recommendation(emotion_text, n=5):\n",
        "    \"\"\"ë¹ ë¥¸ ì¶”ì²œ í•¨ìˆ˜\"\"\"\n",
        "    if 'integrated_system' not in locals() or not integrated_system.get_system_status()['ëª¨ë¸ ë¡œë“œë¨']:\n",
        "        print(\"âŒ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        return None\n",
        "    \n",
        "    return integrated_system.recommend_music(emotion_text, n=n, method='hybrid')\n",
        "\n",
        "def quick_prediction(audio_features):\n",
        "    \"\"\"ë¹ ë¥¸ ì˜ˆì¸¡ í•¨ìˆ˜\"\"\"\n",
        "    if 'integrated_system' not in locals() or not integrated_system.get_system_status()['ëª¨ë¸ ë¡œë“œë¨']:\n",
        "        print(\"âŒ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        return None, None, None\n",
        "    \n",
        "    return integrated_system.predict_music_emotion(audio_features)\n",
        "\n",
        "def analyze_my_playlist(track_names):\n",
        "    \"\"\"ë‚´ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ë¶„ì„\"\"\"\n",
        "    if 'integrated_system' not in locals() or not integrated_system.get_system_status()['ëª¨ë¸ ë¡œë“œë¨']:\n",
        "        print(\"âŒ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        return None, None\n",
        "    \n",
        "    return integrated_system.analyze_playlist_emotion(track_names)\n",
        "\n",
        "def save_current_model(save_path=\"models/my_emotion_model.pth\"):\n",
        "    \"\"\"í˜„ì¬ ëª¨ë¸ ì €ì¥\"\"\"\n",
        "    if 'trainer' not in locals() or not hasattr(trainer, 'model') or trainer.model is None:\n",
        "        print(\"âŒ ì €ì¥í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return False\n",
        "    \n",
        "    return model_manager.save_model(trainer.model, preprocessor, emotion_config, save_path)\n",
        "\n",
        "def load_saved_model(model_path):\n",
        "    \"\"\"ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ\"\"\"\n",
        "    global integrated_system\n",
        "    integrated_system = IntegratedMusicSystem()\n",
        "    return integrated_system.load_from_saved_model(model_path)\n",
        "\n",
        "# í¸ì˜ í•¨ìˆ˜ë“¤ ë“±ë¡\n",
        "print(\"âœ… í¸ì˜ í•¨ìˆ˜ë“¤ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤:\")\n",
        "print(\"   - quick_recommendation('ê¸°ë¶„ ì„¤ëª…', n=5)\")\n",
        "print(\"   - quick_prediction([íŠ¹ì„±ê°’ë“¤])\")\n",
        "print(\"   - analyze_my_playlist(['ê³¡ëª…1', 'ê³¡ëª…2', ...])\")\n",
        "print(\"   - save_current_model('ê²½ë¡œ')\")\n",
        "print(\"   - load_saved_model('ê²½ë¡œ')\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# In[17]:\n",
        "def display_usage_guide():\n",
        "    \"\"\"ì‚¬ìš©ë²• ê°€ì´ë“œ í‘œì‹œ\"\"\"\n",
        "    guide = \"\"\"\n",
        "    ğŸµ Spotify ê°ì • ê¸°ë°˜ ìŒì•… ì¶”ì²œ ì‹œìŠ¤í…œ ì‚¬ìš© ê°€ì´ë“œ\n",
        "    ===============================================\n",
        "    \n",
        "    ğŸ“ 1. ë°ì´í„° ì¤€ë¹„\n",
        "    ----------------\n",
        "    â€¢ Spotify Tracks Datasetì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ 'data/' í´ë”ì— ì €ì¥\n",
        "    â€¢ Spotify YouTube Datasetì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ 'data/' í´ë”ì— ì €ì¥\n",
        "    \n",
        "    ğŸš€ 2. ê¸°ë³¸ ì‚¬ìš©ë²•\n",
        "    -----------------\n",
        "    # ë°ì´í„° ë¡œë“œ\n",
        "    data_loader.load_train_data('data/spotify_tracks_dataset.csv')\n",
        "    data_loader.load_test_data('data/Spotify_Youtube.csv')\n",
        "    \n",
        "    # ë°ì´í„° ì „ì²˜ë¦¬\n",
        "    common_features = data_loader.get_common_features()\n",
        "    X_train, y_train, X_test, y_test = preprocessor.prepare_data(\n",
        "        data_loader.train_df, data_loader.test_df, common_features\n",
        "    )\n",
        "    \n",
        "    # ëª¨ë¸ í•™ìŠµ\n",
        "    model = trainer.train_model(X_train, y_train, X_test, y_test, epochs=80)\n",
        "    \n",
        "    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
        "    integrated_system.initialize_from_trained_components(\n",
        "        trainer.model, preprocessor, emotion_config, data_loader\n",
        "    )\n",
        "    \n",
        "    ğŸ¯ 3. ì£¼ìš” ê¸°ëŠ¥\n",
        "    ---------------\n",
        "    # ìŒì•… ì¶”ì²œ\n",
        "    recommendations = integrated_system.recommend_music('ê¸°ìœ ê¸°ë¶„ì´ì•¼!', n=5)\n",
        "    \n",
        "    # ê°ì • ì˜ˆì¸¡\n",
        "    emotion, confidence, distribution = integrated_system.predict_music_emotion(\n",
        "        [0.8, 0.7, 0.6, 0.3, 0.1, 0.2, 0.1, -6.0, 110.0]\n",
        "    )\n",
        "    \n",
        "    # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ë¶„ì„\n",
        "    emotion, valence = integrated_system.analyze_playlist_emotion(\n",
        "        ['Shape of You', 'Blinding Lights', 'Bohemian Rhapsody']\n",
        "    )\n",
        "    \n",
        "    ğŸ’¾ 4. ëª¨ë¸ ì €ì¥/ë¡œë“œ\n",
        "    -------------------\n",
        "    # ì €ì¥\n",
        "    model_manager.save_model(trainer.model, preprocessor, emotion_config, 'models/my_model.pth')\n",
        "    \n",
        "    # ë¡œë“œ\n",
        "    integrated_system.load_from_saved_model('models/my_model.pth')\n",
        "    \n",
        "    ğŸ­ 5. ì§€ì›í•˜ëŠ” ê°ì •\n",
        "    ------------------\n",
        "    â€¢ ê¸°ì¨ì´ (joy): ê¸°ì¨, í™˜í¬, ì¦ê±°ì›€, í–‰ë³µ, ì‹ ë‚¨ ë“±\n",
        "    â€¢ ìŠ¬í””ì´ (sadness): ìŠ¬í””, ìš°ìš¸, ì¢Œì ˆ, ì™¸ë¡œì›€ ë“±\n",
        "    â€¢ ë²„ëŸ­ì´ (anger): í™”ë‚¨, ë¶„ë…¸, ì§œì¦, ì—´ë°›ìŒ ë“±\n",
        "    â€¢ ì†Œì‹¬ì´ (anxiety): ë¶ˆì•ˆ, ê±±ì •, ì´ˆì¡°, ìŠ¤íŠ¸ë ˆìŠ¤ ë“±\n",
        "    â€¢ ë”°ë¶„ì´ (boredom): ì§€ë£¨í•¨, ì‹¬ì‹¬í•¨, ë¬´ê¸°ë ¥ ë“±\n",
        "    â€¢ ê¹Œì¹ ì´ (grumpy): ê¹Œì¹ í•¨, ì˜ˆë¯¼í•¨, ë¶ˆì¾Œê° ë“±\n",
        "    â€¢ ë¶ˆì•ˆì´ (fear): ë‘ë ¤ì›€, ê³µí¬, ë¬´ì„œì›€ ë“±\n",
        "    â€¢ ë‹¹í™©ì´ (embarrassment): ë‹¹í™©, ì–´ìƒ‰í•¨, ë¯¼ë§í•¨ ë“±\n",
        "    â€¢ ë¶€ëŸ½ì´ (envy): ë¶€ëŸ¬ì›€, ì§ˆíˆ¬ ë“±\n",
        "    â€¢ í‰ì˜¨ (calm): í‰ì˜¨, ì°¨ë¶„í•¨, ì•ˆì •ê° ë“±\n",
        "    \n",
        "    ğŸ”§ 6. ë¬¸ì œ í•´ê²°\n",
        "    ---------------\n",
        "    â€¢ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸: comprehensive_system_check()\n",
        "    â€¢ ë°ì´í„° ì‹œê°í™”: plot_emotion_distribution(), plot_valence_energy_scatter()\n",
        "    â€¢ í•™ìŠµ ê³¼ì • í™•ì¸: trainer.plot_training_history()\n",
        "    \n",
        "    ğŸ“– 7. í¸ì˜ í•¨ìˆ˜\n",
        "    ---------------\n",
        "    â€¢ quick_recommendation('ê°ì • ì„¤ëª…')\n",
        "    â€¢ quick_prediction([íŠ¹ì„±ê°’ë“¤])\n",
        "    â€¢ analyze_my_playlist(['ê³¡ëª…ë“¤'])\n",
        "    â€¢ save_current_model('ê²½ë¡œ')\n",
        "    â€¢ load_saved_model('ê²½ë¡œ')\n",
        "    \"\"\"\n",
        "    \n",
        "    print(guide)\n",
        "\n",
        "# ì‚¬ìš©ë²• ê°€ì´ë“œ í‘œì‹œ\n",
        "display_usage_guide()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ## 18. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦\n",
        "\n",
        "# In[18]:\n",
        "def run_comprehensive_test():\n",
        "    \"\"\"ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰\"\"\"\n",
        "    print(\"ğŸ§ª ì¢…í•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    test_results = {\n",
        "        'data_loading': False,\n",
        "        'preprocessing': False,\n",
        "        'model_training': False,\n",
        "        'recommendation': False,\n",
        "        'prediction': False,\n",
        "        'playlist_analysis': False\n",
        "    }\n",
        "    \n",
        "    # 1. ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸\n",
        "    print(\"1. ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸...\")\n",
        "    if hasattr(data_loader, 'train_df') and data_loader.train_df is not None:\n",
        "        if hasattr(data_loader, 'test_df') and data_loader.test_df is not None:\n",
        "            test_results['data_loading'] = True\n",
        "            print(\"   âœ… ë°ì´í„° ë¡œë”© ì„±ê³µ\")\n",
        "        else:\n",
        "            print(\"   âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨\")\n",
        "    else:\n",
        "        print(\"   âŒ í•™ìŠµ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨\")\n",
        "    \n",
        "    # 2. ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n",
        "    print(\"2. ë°ì´í„° ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸...\")\n",
        "    if 'X_train' in locals() and X_train is not None:\n",
        "        test_results['preprocessing'] = True\n",
        "        print(\"   âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì„±ê³µ\")\n",
        "    else:\n",
        "        print(\"   âŒ ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨\")\n",
        "    \n",
        "    # 3. ëª¨ë¸ í•™ìŠµ í…ŒìŠ¤íŠ¸\n",
        "    print(\"3. ëª¨ë¸ í•™ìŠµ í…ŒìŠ¤íŠ¸...\")\n",
        "    if hasattr(trainer, 'model') and trainer.model is not None:\n",
        "        test_results['model_training'] = True\n",
        "        print(\"   âœ… ëª¨ë¸ í•™ìŠµ ì„±ê³µ\")\n",
        "    else:\n",
        "        print(\"   âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨\")\n",
        "    \n",
        "    # 4. ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\n",
        "    print(\"4. ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸...\")\n",
        "    if 'integrated_system' in locals() and integrated_system.get_system_status()['ì¶”ì²œ ì‹œìŠ¤í…œ ì¤€ë¹„ë¨']:\n",
        "        try:\n",
        "            test_rec = integrated_system.recommend_music('ê¸°ì¨', n=1)\n",
        "            if not test_rec.empty:\n",
        "                test_results['recommendation'] = True\n",
        "                print(\"   âœ… ì¶”ì²œ ì‹œìŠ¤í…œ ì„±ê³µ\")\n",
        "            else:\n",
        "                print(\"   âš ï¸ ì¶”ì²œ ì‹œìŠ¤í…œ ì‘ë™í•˜ì§€ë§Œ ê²°ê³¼ ì—†ìŒ\")\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ ì¶”ì²œ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}\")\n",
        "    else:\n",
        "        print(\"   âŒ ì¶”ì²œ ì‹œìŠ¤í…œ ë¯¸ì¤€ë¹„\")\n",
        "    \n",
        "    # 5. ê°ì • ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸\n",
        "    print(\"5. ê°ì • ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸...\")\n",
        "    if 'integrated_system' in locals() and integrated_system.get_system_status()['ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì¤€ë¹„ë¨']:\n",
        "        try:\n",
        "            test_features = [0.8, 0.7, 0.6, 0.3, 0.1, 0.2, 0.1, -6.0, 110.0]\n",
        "            emotion, confidence, _ = integrated_system.predict_music_emotion(test_features)\n",
        "            if emotion:\n",
        "                test_results['prediction'] = True\n",
        "                print(f\"   âœ… ê°ì • ì˜ˆì¸¡ ì„±ê³µ (ê²°ê³¼: {emotion})\")\n",
        "            else:\n",
        "                print(\"   âŒ ê°ì • ì˜ˆì¸¡ ì‹¤íŒ¨\")\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ ê°ì • ì˜ˆì¸¡ ì˜¤ë¥˜: {e}\")\n",
        "    else:\n",
        "        print(\"   âŒ ê°ì • ì˜ˆì¸¡ ì‹œìŠ¤í…œ ë¯¸ì¤€ë¹„\")\n",
        "    \n",
        "    # 6. í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ë¶„ì„ í…ŒìŠ¤íŠ¸\n",
        "    print(\"6. í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ë¶„ì„ í…ŒìŠ¤íŠ¸...\")\n",
        "    if 'integrated_system' in locals() and integrated_system.get_system_status()['ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì¤€ë¹„ë¨']:\n",
        "        try:\n",
        "            # ì‹¤ì œ ì¡´ì¬í•  ê°€ëŠ¥ì„±ì´ ë†’ì€ ê³¡ëª…ë“¤ë¡œ í…ŒìŠ¤íŠ¸\n",
        "            test_playlist = ['test_track_1', 'test_track_2']  # ì‹¤ì œ ë°ì´í„°ì— ë§ê²Œ ìˆ˜ì • í•„ìš”\n",
        "            emotion, valence = integrated_system.analyze_playlist_emotion(test_playlist)\n",
        "            if emotion is not None:\n",
        "                test_results['playlist_analysis'] = True\n",
        "                print(f\"   âœ… í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ë¶„ì„ ì„±ê³µ\")\n",
        "            else:\n",
        "                print(\"   âš ï¸ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ë¶„ì„ - í•´ë‹¹ íŠ¸ë™ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ (ì •ìƒ)\")\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
        "    else:\n",
        "        print(\"   âŒ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ë¶„ì„ ì‹œìŠ¤í…œ ë¯¸ì¤€ë¹„\")\n",
        "    \n",
        "    # ê²°ê³¼ ìš”ì•½\n",
        "    print(f\"\\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    passed_tests = sum(test_results.values())\n",
        "    total_tests = len(test_results)\n",
        "    \n",
        "    for test_name, result in test_results.items():\n",
        "        icon = \"âœ…\" if result else \"âŒ\"\n",
        "        print(f\"   {icon} {test_name.replace('_', ' ').title()}\")\n",
        "    \n",
        "    print(f\"\\nğŸ¯ ì „ì²´ ê²°ê³¼: {passed_tests}/{total_tests} í…ŒìŠ¤íŠ¸ í†µê³¼\")\n",
        "    \n",
        "    if passed_tests == total_tests:\n",
        "        print(\"ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ì‹œìŠ¤í…œì´ ì™„ì „íˆ ì‘ë™í•©ë‹ˆë‹¤.\")\n",
        "    elif passed_tests >= total_tests * 0.7:\n",
        "        print(\"ğŸ‘ ëŒ€ë¶€ë¶„ì˜ ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.\")\n",
        "    else:\n",
        "        print(\"âš ï¸ ì¼ë¶€ ê¸°ëŠ¥ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "    \n",
        "    return test_results\n",
        "\n",
        "# ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
        "test_results = run_comprehensive_test()\n",
        "\n",
        "# ## 19. ë§ˆë¬´ë¦¬ ë° ì •ë¦¬\n",
        "\n",
        "# In[19]:\n",
        "print(\"ğŸµ Spotify ê°ì • ê¸°ë°˜ ìŒì•… ì¶”ì²œ ì‹œìŠ¤í…œ\")\n",
        "print(\"=\" * 60)\n",
        "print(\"âœ… ì£¼í”¼í„° ë…¸íŠ¸ë¶ ë²„ì „ ì„¤ì • ì™„ë£Œ!\")\n",
        "print()\n",
        "print(\"ğŸ“‹ ì£¼ìš” êµ¬ì„± ìš”ì†Œ:\")\n",
        "print(\"   â€¢ EmotionConfig: ê°ì • ì„¤ì • ë° ë§¤í•‘\")\n",
        "print(\"   â€¢ DataLoader: ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬\")\n",
        "print(\"   â€¢ MusicEmotionClassifier: ì‹ ê²½ë§ ëª¨ë¸\")\n",
        "print(\"   â€¢ ModelTrainer: ëª¨ë¸ í•™ìŠµ\")\n",
        "print(\"   â€¢ MusicRecommendationSystem: ìŒì•… ì¶”ì²œ\")\n",
        "print(\"   â€¢ EmotionPredictor: ê°ì • ì˜ˆì¸¡\")\n",
        "print(\"   â€¢ IntegratedMusicSystem: í†µí•© ì‹œìŠ¤í…œ\")\n",
        "print()\n",
        "print(\"ğŸ¯ ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥:\")\n",
        "print(\"   â€¢ ê°ì •ë³„ ìŒì•… ì¶”ì²œ (9ê°€ì§€ ê°ì •)\")\n",
        "print(\"   â€¢ ìŒí–¥ íŠ¹ì„± ê¸°ë°˜ ê°ì • ì˜ˆì¸¡\")\n",
        "print(\"   â€¢ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ê°ì • ë¶„ì„\")\n",
        "print(\"   â€¢ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜\")\n",
        "print(\"   â€¢ ëª¨ë¸ ì €ì¥/ë¡œë“œ\")\n",
        "print(\"   â€¢ ë°ì´í„° ì‹œê°í™”\")\n",
        "print()\n",
        "print(\"ğŸ’¡ ë¹ ë¥¸ ì‹œì‘:\")\n",
        "print(\"   1. ë°ì´í„° íŒŒì¼ì„ 'data/' í´ë”ì— ì €ì¥\")\n",
        "print(\"   2. ì…€ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰\")\n",
        "print(\"   3. quick_recommendation('ê¸°ë¶„ ì„¤ëª…') í•¨ìˆ˜ ì‚¬ìš©\")\n",
        "print()\n",
        "print(\"ğŸ”§ ë¬¸ì œ í•´ê²°:\")\n",
        "print(\"   â€¢ comprehensive_system_check() - ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸\")\n",
        "print(\"   â€¢ display_usage_guide() - ìƒì„¸ ì‚¬ìš©ë²•\")\n",
        "print(\"   â€¢ run_comprehensive_test() - ì „ì²´ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\")\n",
        "print()\n",
        "print(\"ğŸ‰ ìŒì•…ê³¼ ê°ì •ì˜ ì•„ë¦„ë‹¤ìš´ ë§Œë‚¨ì„ ì¦ê¸°ì„¸ìš”!\")\n",
        "\n",
        "# ë§ˆì§€ë§‰ ìƒíƒœ í™•ì¸\n",
        "if 'integrated_system' in locals():\n",
        "    final_status = integrated_system.get_system_status()\n",
        "    ready_components = sum(final_status.values())\n",
        "    total_components = len(final_status)\n",
        "    \n",
        "    if ready_components == total_components:\n",
        "        print(f\"\\nğŸš€ ì‹œìŠ¤í…œ ì™„ì „ ì¤€ë¹„ ì™„ë£Œ! ({ready_components}/{total_components})\")\n",
        "        print(\"ì´ì œ ëª¨ë“  ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "    else:\n",
        "        print(f\"\\nâš ï¸ ì‹œìŠ¤í…œ ë¶€ë¶„ ì¤€ë¹„ ({ready_components}/{total_components})\")\n",
        "        print(\"ì¼ë¶€ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì¶”ê°€ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸ í†µí•© ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "    print(\"ìœ„ì˜ ì…€ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")# ## ğŸµ Spotify ê°ì • ê¸°ë°˜ ìŒì•… ì¶”ì²œ ì‹œìŠ¤í…œ\n",
        "# "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
