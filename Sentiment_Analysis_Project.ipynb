{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kagglehub in c:\\programdata\\anaconda3\\lib\\site-packages (0.2.9)Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: requests in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from kagglehub) (2.28.2)\n",
            "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from kagglehub) (20.4)\n",
            "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from kagglehub) (4.50.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2020.6.20)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kagglehub) (1.25.11)\n",
            "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->kagglehub) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->kagglehub) (2.4.7)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pip install kagglehub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-c4TYcMCGhUe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.12)\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "madhavmalhotra_journal_entries_with_labelled_emotions_path = kagglehub.dataset_download('madhavmalhotra/journal-entries-with-labelled-emotions')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:43.733383Z",
          "iopub.status.busy": "2023-12-01T02:47:43.732931Z",
          "iopub.status.idle": "2023-12-01T02:47:44.158827Z",
          "shell.execute_reply": "2023-12-01T02:47:44.157642Z",
          "shell.execute_reply.started": "2023-12-01T02:47:43.733346Z"
        },
        "id": "jNGKDvO_GhUg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:44.161528Z",
          "iopub.status.busy": "2023-12-01T02:47:44.160842Z",
          "iopub.status.idle": "2023-12-01T02:47:44.198282Z",
          "shell.execute_reply": "2023-12-01T02:47:44.197159Z",
          "shell.execute_reply.started": "2023-12-01T02:47:44.161497Z"
        },
        "id": "n9jwWsoIGhUi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "df = pd.read_csv(r'C:\\Users\\USER\\Downloads\\dataset\\data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:44.200136Z",
          "iopub.status.busy": "2023-12-01T02:47:44.199669Z",
          "iopub.status.idle": "2023-12-01T02:47:44.2629Z",
          "shell.execute_reply": "2023-12-01T02:47:44.262181Z",
          "shell.execute_reply.started": "2023-12-01T02:47:44.200099Z"
        },
        "id": "dtoCUL3VGhUk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.replace({False: 0, True: 1}, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:48:19.925923Z",
          "iopub.status.busy": "2023-12-01T02:48:19.925404Z",
          "iopub.status.idle": "2023-12-01T02:48:19.934867Z",
          "shell.execute_reply": "2023-12-01T02:48:19.932494Z",
          "shell.execute_reply.started": "2023-12-01T02:48:19.925886Z"
        },
        "id": "FqCacPdKGhUl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print((df.iloc[0]['Answer']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:44.272071Z",
          "iopub.status.busy": "2023-12-01T02:47:44.271731Z",
          "iopub.status.idle": "2023-12-01T02:47:48.996481Z",
          "shell.execute_reply": "2023-12-01T02:47:48.995667Z",
          "shell.execute_reply.started": "2023-12-01T02:47:44.272043Z"
        },
        "id": "XfdvQysbGhUm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 불러오기 (NLTK: 자연어 처리 도구 모음)\n",
        "import nltk\n",
        "from nltk.corpus import stopwords  # 불용어 사전 (의미 없는 단어들)\n",
        "from nltk.tokenize import word_tokenize  # 문장을 단어로 나누는 함수\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer  # 감정 분석기 (VADER)\n",
        "sia = SentimentIntensityAnalyzer()  # VADER 감정 분석기 객체 생성\n",
        "import string  # 문자열 처리를 위한 표준 라이브러리\n",
        "\n",
        "# CSV 파일 불러오기 (감정이 라벨링된 일기 데이터)\n",
        "df = pd.read_csv('/kaggle/input/journal-entries-with-labelled-emotions/data.csv')\n",
        "\n",
        "# True/False 값을 1/0으로 변환 (모델 학습을 위한 정수 처리)\n",
        "df.replace({False: 0, True: 1}, inplace=True)\n",
        "\n",
        "# 감정 점수를 저장할 리스트 초기화\n",
        "list_pos = []       # 긍정 점수\n",
        "list_neg = []       # 부정 점수\n",
        "list_neu = []       # 중립 점수\n",
        "list_compound = []  # 종합 감정 점수 (-1~1)\n",
        "\n",
        "# 데이터프레임의 모든 행을 순회하면서 텍스트 정제 및 감정 점수 추출\n",
        "for row in range(0, df.shape[0]):\n",
        "\n",
        "    # 현재 행의 'Answer' 열(일기 문장)을 가져오기\n",
        "    example_sent = df.iloc[row]['Answer']\n",
        "\n",
        "    # 문장 부호 제거 (텍스트 정제)\n",
        "    example_sent = example_sent.replace(r'.', '')\n",
        "    example_sent = example_sent.replace(r',', '')\n",
        "    example_sent = example_sent.replace(r'!', '')\n",
        "    example_sent = example_sent.replace(r';', '')\n",
        "    example_sent = example_sent.replace(r'?', '')\n",
        "    example_sent = example_sent.replace(r'(', '')\n",
        "    example_sent = example_sent.replace(r')', '')\n",
        "    example_sent = example_sent.replace(r\"'\", '')\n",
        "\n",
        "    # 영어 불용어 리스트 불러오기 (예: I, is, the 등)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # 일반적인 축약형 표현도 불용어로 추가\n",
        "    list_contractions_common = {\n",
        "        'arent', 'cant', 'couldnt', 'didnt', 'doesnt', 'dont',\n",
        "        'hadnt', 'havent', 'shouldnt', 'wouldnt',\n",
        "        'youve', 'youre', 'wont', 'werent', 'weve', 'wed',\n",
        "        'theyre', 'Im'\n",
        "    }\n",
        "    stop_words.update(list_contractions_common)\n",
        "\n",
        "    # 문장을 단어 단위로 분할 (토큰화)\n",
        "    word_tokens = word_tokenize(example_sent)\n",
        "\n",
        "    # 소문자로 바꾸고 stop_words에 포함된 단어 제거\n",
        "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "\n",
        "    # (의도상 오류) 위에서 생성한 filtered_sentence를 빈 리스트로 다시 초기화 → 앞의 작업이 무효됨\n",
        "    filtered_sentence = []\n",
        "\n",
        "    # 다시 토큰 순회하면서 불용어 제거 (소문자 변환 없음)\n",
        "    for w in word_tokens:\n",
        "        if w not in stop_words:\n",
        "            filtered_sentence.append(w)\n",
        "\n",
        "    # 단어 리스트를 다시 하나의 문장으로 결합\n",
        "    filtered_sentence = ' '.join(filtered_sentence)\n",
        "\n",
        "    # 전처리된 문장으로 원래 'Answer' 열을 업데이트\n",
        "    df.at[row, 'Answer'] = filtered_sentence\n",
        "\n",
        "    # 감정 점수 추출: VADER가 반환하는 점수 중 각 항목만 따로 저장\n",
        "    list_pos.append(sia.polarity_scores(filtered_sentence)['pos'])        # 긍정 점수\n",
        "    list_neg.append(sia.polarity_scores(filtered_sentence)['neg'])        # 부정 점수\n",
        "    list_neu.append(sia.polarity_scores(filtered_sentence)['neu'])        # 중립 점수\n",
        "    list_compound.append(sia.polarity_scores(filtered_sentence)['compound'])  # 종합 점수\n",
        "\n",
        "# 감정 점수 리스트를 원본 데이터프레임에 새로운 열로 추가\n",
        "df['positive_score'] = list_pos\n",
        "df['negative_score'] = list_neg\n",
        "df['neutral_score'] = list_neu\n",
        "df['compound_score'] = list_compound\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:48.998448Z",
          "iopub.status.busy": "2023-12-01T02:47:48.997654Z",
          "iopub.status.idle": "2023-12-01T02:47:49.02201Z",
          "shell.execute_reply": "2023-12-01T02:47:49.020907Z",
          "shell.execute_reply.started": "2023-12-01T02:47:48.99842Z"
        },
        "id": "dXI5Qxs2GhUn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:49.024403Z",
          "iopub.status.busy": "2023-12-01T02:47:49.023298Z",
          "iopub.status.idle": "2023-12-01T02:47:49.030164Z",
          "shell.execute_reply": "2023-12-01T02:47:49.029162Z",
          "shell.execute_reply.started": "2023-12-01T02:47:49.024365Z"
        },
        "id": "JxS3ko_XGhUo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print((df.iloc[8]['Answer']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:49.031968Z",
          "iopub.status.busy": "2023-12-01T02:47:49.031485Z",
          "iopub.status.idle": "2023-12-01T02:47:49.051533Z",
          "shell.execute_reply": "2023-12-01T02:47:49.050527Z",
          "shell.execute_reply.started": "2023-12-01T02:47:49.031932Z"
        },
        "id": "7Qm76UPYGhUo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# VADER 감정 분석기를 nltk에서 불러옴\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# 감정 분석기 객체 생성\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "sia.polarity_scores(df.iloc[8]['Answer'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:49.053735Z",
          "iopub.status.busy": "2023-12-01T02:47:49.052981Z",
          "iopub.status.idle": "2023-12-01T02:47:49.078755Z",
          "shell.execute_reply": "2023-12-01T02:47:49.07777Z",
          "shell.execute_reply.started": "2023-12-01T02:47:49.05368Z"
        },
        "id": "PMOjxtQmGhUp",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:49.08368Z",
          "iopub.status.busy": "2023-12-01T02:47:49.083359Z",
          "iopub.status.idle": "2023-12-01T02:47:49.093135Z",
          "shell.execute_reply": "2023-12-01T02:47:49.091929Z",
          "shell.execute_reply.started": "2023-12-01T02:47:49.083653Z"
        },
        "id": "xa5nGseaGhUq",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.rename(columns={\"Answer.f1.afraid.raw\": \"afraid\",\n",
        "                   \"Answer.f1.angry.raw\": \"angry\",\n",
        "                   \"Answer.f1.anxious.raw\": \"anxious\",\n",
        "                   \"Answer.f1.ashamed.raw\": \"ashamed\",\n",
        "                   \"Answer.f1.awkward.raw\": \"awkward\",\n",
        "                   \"Answer.f1.bored.raw\": \"bored\",\n",
        "                   \"Answer.f1.calm.raw\": \"calm\",\n",
        "                   \"Answer.f1.confused.raw\": \"confused\",\n",
        "                   \"Answer.f1.disgusted.raw\": \"disgusted\",\n",
        "                   \"Answer.f1.excited.raw\": \"excited\",\n",
        "                   \"Answer.f1.frustrated.raw\": \"frustrated\",\n",
        "                   \"Answer.f1.happy.raw\": \"happy\",\n",
        "                   \"Answer.f1.jealous.raw\": \"jealous\",\n",
        "                   \"Answer.f1.nostalgic.raw\": \"nostalgic\",\n",
        "                   \"Answer.f1.proud.raw\": \"proud\",\n",
        "                   \"Answer.f1.sad.raw\": \"sad\",\n",
        "                   \"Answer.f1.satisfied.raw\": \"satisfied\",\n",
        "                   \"Answer.f1.surprised.raw\": \"surprised\",\n",
        "                   \"Answer.t1.exercise.raw\": \"exercise\",\n",
        "                   \"Answer.t1.family.raw\": \"family\",\n",
        "                   \"Answer.t1.food.raw\": \"food\",\n",
        "                   \"Answer.t1.friends.raw\": \"friends\",\n",
        "                   \"Answer.t1.god.raw\": \"god\",\n",
        "                   \"Answer.t1.health.raw\": \"health\",\n",
        "                   \"Answer.t1.love.raw\": \"love\",\n",
        "                   \"Answer.t1.recreation.raw\": \"recreation\",\n",
        "                   \"Answer.t1.school.raw\": \"school\",\n",
        "                   \"Answer.t1.sleep.raw\": \"sleep\",\n",
        "                   \"Answer.t1.work.raw\": \"work\",\n",
        "                  }, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:49.094785Z",
          "iopub.status.busy": "2023-12-01T02:47:49.094296Z",
          "iopub.status.idle": "2023-12-01T02:47:49.120917Z",
          "shell.execute_reply": "2023-12-01T02:47:49.119777Z",
          "shell.execute_reply.started": "2023-12-01T02:47:49.094753Z"
        },
        "id": "IfzExC1yGhUq",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:49.12308Z",
          "iopub.status.busy": "2023-12-01T02:47:49.122663Z",
          "iopub.status.idle": "2023-12-01T02:47:49.129494Z",
          "shell.execute_reply": "2023-12-01T02:47:49.128495Z",
          "shell.execute_reply.started": "2023-12-01T02:47:49.123045Z"
        },
        "id": "0mIuDN87GhUr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(df.iloc[0][12])\n",
        "print(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:49.131689Z",
          "iopub.status.busy": "2023-12-01T02:47:49.130751Z",
          "iopub.status.idle": "2023-12-01T02:47:49.139402Z",
          "shell.execute_reply": "2023-12-01T02:47:49.13858Z",
          "shell.execute_reply.started": "2023-12-01T02:47:49.131654Z"
        },
        "id": "2jIiywy0GhUr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "colname = df.columns[18]\n",
        "print(colname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:49.141454Z",
          "iopub.status.busy": "2023-12-01T02:47:49.140845Z",
          "iopub.status.idle": "2023-12-01T02:47:51.319641Z",
          "shell.execute_reply": "2023-12-01T02:47:51.318476Z",
          "shell.execute_reply.started": "2023-12-01T02:47:49.141419Z"
        },
        "id": "QD5cEcDFGhUs",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#18 emotions\n",
        "#columns 1-18 (inclusive of both)\n",
        "final_emotion_list = []\n",
        "for row in range (0, len(df)):\n",
        "    emotion_list = []\n",
        "    for col in range (1, 19):\n",
        "        if (df.iloc[row][col] == 1):\n",
        "            emotion_list.append(df.columns[col])\n",
        "    final_emotion_list.append(emotion_list)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:51.321206Z",
          "iopub.status.busy": "2023-12-01T02:47:51.320905Z",
          "iopub.status.idle": "2023-12-01T02:47:51.328355Z",
          "shell.execute_reply": "2023-12-01T02:47:51.32707Z",
          "shell.execute_reply.started": "2023-12-01T02:47:51.321182Z"
        },
        "id": "gosM3cY6GhUs",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(len(final_emotion_list))\n",
        "print((final_emotion_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:51.330593Z",
          "iopub.status.busy": "2023-12-01T02:47:51.329597Z",
          "iopub.status.idle": "2023-12-01T02:47:51.338488Z",
          "shell.execute_reply": "2023-12-01T02:47:51.337387Z",
          "shell.execute_reply.started": "2023-12-01T02:47:51.330545Z"
        },
        "id": "Iy8GbYuKGhUs",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df['Emotions Felt'] = final_emotion_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:51.34039Z",
          "iopub.status.busy": "2023-12-01T02:47:51.340073Z",
          "iopub.status.idle": "2023-12-01T02:47:51.368323Z",
          "shell.execute_reply": "2023-12-01T02:47:51.366598Z",
          "shell.execute_reply.started": "2023-12-01T02:47:51.340365Z"
        },
        "id": "Bf0Qm_S_GhUt",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:51.370626Z",
          "iopub.status.busy": "2023-12-01T02:47:51.370244Z",
          "iopub.status.idle": "2023-12-01T02:47:51.377066Z",
          "shell.execute_reply": "2023-12-01T02:47:51.375546Z",
          "shell.execute_reply.started": "2023-12-01T02:47:51.370595Z"
        },
        "id": "5d25ZrkfGhUt",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:51.380489Z",
          "iopub.status.busy": "2023-12-01T02:47:51.379079Z",
          "iopub.status.idle": "2023-12-01T02:47:52.859215Z",
          "shell.execute_reply": "2023-12-01T02:47:52.858169Z",
          "shell.execute_reply.started": "2023-12-01T02:47:51.380444Z"
        },
        "id": "6qRr8a-2GhUt",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#11 topics\n",
        "#columns 18-29 (inclusive of both)\n",
        "#no topic lists greater than one for one person/entry, so we can just append it to one list\n",
        "final_topic_list = []\n",
        "for row in range (0, len(df)):\n",
        "    #topic_list = []\n",
        "    for col in range (19, 30):\n",
        "        if (df.iloc[row][col] == 1):\n",
        "            final_topic_list.append(df.columns[col])\n",
        "#no topic lists greater than one, so"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:52.861541Z",
          "iopub.status.busy": "2023-12-01T02:47:52.86084Z",
          "iopub.status.idle": "2023-12-01T02:47:52.867301Z",
          "shell.execute_reply": "2023-12-01T02:47:52.866297Z",
          "shell.execute_reply.started": "2023-12-01T02:47:52.861505Z"
        },
        "id": "-LRLDF49GhUt",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(len(final_topic_list))\n",
        "print((final_topic_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:52.868952Z",
          "iopub.status.busy": "2023-12-01T02:47:52.868318Z",
          "iopub.status.idle": "2023-12-01T02:47:54.229829Z",
          "shell.execute_reply": "2023-12-01T02:47:54.228752Z",
          "shell.execute_reply.started": "2023-12-01T02:47:52.868926Z"
        },
        "id": "KqNnOCQgGhUt",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#There are two rows which don't have any reason selected, let's find them:\n",
        "\n",
        "for row in range (0, len(df)):\n",
        "    #topic_list = []\n",
        "    count = 0\n",
        "    for col in range (19, 30):\n",
        "        if (df.iloc[row][col] == 1):\n",
        "            count = count + 1\n",
        "    if (count == 0):\n",
        "        print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:54.231424Z",
          "iopub.status.busy": "2023-12-01T02:47:54.231121Z",
          "iopub.status.idle": "2023-12-01T02:47:54.239211Z",
          "shell.execute_reply": "2023-12-01T02:47:54.238114Z",
          "shell.execute_reply.started": "2023-12-01T02:47:54.231399Z"
        },
        "id": "0OzJZf_UGhUu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(df.iloc[961][0])\n",
        "# seems to be because of work\n",
        "print(df.iloc[961][34])\n",
        "print(df.iloc[961][33])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:54.241112Z",
          "iopub.status.busy": "2023-12-01T02:47:54.240537Z",
          "iopub.status.idle": "2023-12-01T02:47:54.248671Z",
          "shell.execute_reply": "2023-12-01T02:47:54.247695Z",
          "shell.execute_reply.started": "2023-12-01T02:47:54.241083Z"
        },
        "id": "W6jd7ukPGhUu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(df.iloc[980][0])\n",
        "#seems to be because of god\n",
        "print(df.iloc[980][34])\n",
        "print(df.iloc[980][33])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:54.250421Z",
          "iopub.status.busy": "2023-12-01T02:47:54.250122Z",
          "iopub.status.idle": "2023-12-01T02:47:54.259782Z",
          "shell.execute_reply": "2023-12-01T02:47:54.258786Z",
          "shell.execute_reply.started": "2023-12-01T02:47:54.250394Z"
        },
        "id": "rh2qmiWVGhUu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#now let's add the labels into the dataframe\n",
        "#first one is for work which is col 29\n",
        "df.iat[961,29] = 1\n",
        "print(df.iloc[961][29])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:54.261264Z",
          "iopub.status.busy": "2023-12-01T02:47:54.260969Z",
          "iopub.status.idle": "2023-12-01T02:47:54.270997Z",
          "shell.execute_reply": "2023-12-01T02:47:54.269929Z",
          "shell.execute_reply.started": "2023-12-01T02:47:54.26124Z"
        },
        "id": "QyRgKQ-2GhUu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#now let's add the labels into the dataframe\n",
        "#second one is for god which is col 23\n",
        "print(df.iloc[980][23])\n",
        "df.iat[980,23] = 1\n",
        "print(df.iloc[980][23])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:54.272895Z",
          "iopub.status.busy": "2023-12-01T02:47:54.272566Z",
          "iopub.status.idle": "2023-12-01T02:47:55.634614Z",
          "shell.execute_reply": "2023-12-01T02:47:55.633694Z",
          "shell.execute_reply.started": "2023-12-01T02:47:54.272868Z"
        },
        "id": "M9u-3rguGhUu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Now, let's rerun the code to get all the topics and the length should be correct\n",
        "#11 topics\n",
        "#columns 18-29 (inclusive of both)\n",
        "#no topic lists greater than one for one person/entry, so we can just append it to one list\n",
        "final_topic_list = []\n",
        "for row in range (0, len(df)):\n",
        "    #topic_list = []\n",
        "    for col in range (19, 30):\n",
        "        if (df.iloc[row][col] == 1):\n",
        "            final_topic_list.append(df.columns[col])\n",
        "#no topic lists greater than one, so"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:55.636287Z",
          "iopub.status.busy": "2023-12-01T02:47:55.63599Z",
          "iopub.status.idle": "2023-12-01T02:47:55.64188Z",
          "shell.execute_reply": "2023-12-01T02:47:55.640758Z",
          "shell.execute_reply.started": "2023-12-01T02:47:55.636262Z"
        },
        "id": "H2I2Huw0GhUv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(len(final_topic_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:55.650183Z",
          "iopub.status.busy": "2023-12-01T02:47:55.649865Z",
          "iopub.status.idle": "2023-12-01T02:47:55.675122Z",
          "shell.execute_reply": "2023-12-01T02:47:55.673823Z",
          "shell.execute_reply.started": "2023-12-01T02:47:55.650158Z"
        },
        "id": "UMhcHUMOGhUv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df['Emotion Topic'] = final_topic_list\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:55.677539Z",
          "iopub.status.busy": "2023-12-01T02:47:55.67643Z",
          "iopub.status.idle": "2023-12-01T02:47:55.69919Z",
          "shell.execute_reply": "2023-12-01T02:47:55.698046Z",
          "shell.execute_reply.started": "2023-12-01T02:47:55.677496Z"
        },
        "id": "Bj_N3olfGhUw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df2 = df.copy()\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:55.700819Z",
          "iopub.status.busy": "2023-12-01T02:47:55.700534Z",
          "iopub.status.idle": "2023-12-01T02:47:55.721402Z",
          "shell.execute_reply": "2023-12-01T02:47:55.720302Z",
          "shell.execute_reply.started": "2023-12-01T02:47:55.700796Z"
        },
        "id": "okgfuzhWGhUw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#dropping all the cols for emotions now that we have a comprehensive one at the end\n",
        "df2 = df2.drop(df2.iloc[:, 1:19],axis = 1)\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:55.723223Z",
          "iopub.status.busy": "2023-12-01T02:47:55.722847Z",
          "iopub.status.idle": "2023-12-01T02:47:55.744943Z",
          "shell.execute_reply": "2023-12-01T02:47:55.743779Z",
          "shell.execute_reply.started": "2023-12-01T02:47:55.723195Z"
        },
        "id": "Fubxh24uGhUw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#dropping all the cols for emotion topics now that we have a comprehensive one at the end\n",
        "df2 = df2.drop(df2.iloc[:, 1:12],axis = 1)\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:55.746572Z",
          "iopub.status.busy": "2023-12-01T02:47:55.746184Z",
          "iopub.status.idle": "2023-12-01T02:47:55.766287Z",
          "shell.execute_reply": "2023-12-01T02:47:55.765237Z",
          "shell.execute_reply.started": "2023-12-01T02:47:55.746543Z"
        },
        "id": "LWGzUTacGhUw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#swapping emotion topic and emotions felt columns\n",
        "emotions_felt_list = df2['Emotions Felt']\n",
        "#print(emotions_felt_list)\n",
        "df2.drop(columns = ['Emotions Felt'], inplace = True)\n",
        "#df2.head()\n",
        "df2['Emotions Felt'] = emotions_felt_list\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:55.768066Z",
          "iopub.status.busy": "2023-12-01T02:47:55.767617Z",
          "iopub.status.idle": "2023-12-01T02:47:55.775584Z",
          "shell.execute_reply": "2023-12-01T02:47:55.774498Z",
          "shell.execute_reply.started": "2023-12-01T02:47:55.768029Z"
        },
        "id": "_rvUm_VSGhUx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(df2.iloc[0][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:55.777438Z",
          "iopub.status.busy": "2023-12-01T02:47:55.777129Z",
          "iopub.status.idle": "2023-12-01T02:47:55.795282Z",
          "shell.execute_reply": "2023-12-01T02:47:55.794405Z",
          "shell.execute_reply.started": "2023-12-01T02:47:55.777413Z"
        },
        "id": "yEM0LcitGhUx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_copied = df2.copy()\n",
        "df_copied.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:55.796813Z",
          "iopub.status.busy": "2023-12-01T02:47:55.796509Z",
          "iopub.status.idle": "2023-12-01T02:47:55.812321Z",
          "shell.execute_reply": "2023-12-01T02:47:55.811286Z",
          "shell.execute_reply.started": "2023-12-01T02:47:55.796787Z"
        },
        "id": "s3vNYu8vGhUx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_copied2 = df2.copy()\n",
        "df_copied2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:55.813669Z",
          "iopub.status.busy": "2023-12-01T02:47:55.813374Z",
          "iopub.status.idle": "2023-12-01T02:47:55.819291Z",
          "shell.execute_reply": "2023-12-01T02:47:55.818022Z",
          "shell.execute_reply.started": "2023-12-01T02:47:55.813644Z"
        },
        "id": "SLE3UpcDGhUx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "positive_emotions = ['satisfied', 'calm', 'happy', 'nostalgic', 'excited', 'proud', 'surprised']\n",
        "negative_emotions = ['afraid', 'anxious', 'awkward', 'confused', 'ashamed', 'sad', 'angry', 'frustrated', 'disgusted', 'bored', 'jealous']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:55.821071Z",
          "iopub.status.busy": "2023-12-01T02:47:55.820705Z",
          "iopub.status.idle": "2023-12-01T02:47:55.829821Z",
          "shell.execute_reply": "2023-12-01T02:47:55.828766Z",
          "shell.execute_reply.started": "2023-12-01T02:47:55.821038Z"
        },
        "id": "m_XmG_0sGhUy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(set(['happy']).issubset(set(['happy', 'sad', 'anxious', 'excited'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:55.831425Z",
          "iopub.status.busy": "2023-12-01T02:47:55.831163Z",
          "iopub.status.idle": "2023-12-01T02:47:56.222909Z",
          "shell.execute_reply": "2023-12-01T02:47:56.221889Z",
          "shell.execute_reply.started": "2023-12-01T02:47:55.831403Z"
        },
        "id": "0UeKpiC1GhUy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#864 entries in last column which have more than one entry in the emotions list\n",
        "import random\n",
        "positive_emotions = {'satisfied', 'calm', 'happy', 'nostalgic', 'excited', 'proud', 'surprised'}\n",
        "negative_emotions = {'afraid', 'anxious', 'awkward', 'confused', 'ashamed', 'sad', 'angry', 'frustrated', 'disgusted', 'bored', 'jealous'}\n",
        "p1 = {'satisfied', 'calm', 'happy', 'nostalgic'}\n",
        "p2 = {'excited', 'proud', 'surprised'}\n",
        "\n",
        "n1 = {'afraid', 'anxious', 'awkward', 'confused', 'ashamed', 'sad'}\n",
        "n2 = {'angry', 'frustrated', 'disgusted', 'bored', 'jealous'}\n",
        "\n",
        "for row in range (0, len(df_copied)):\n",
        "    #topic_list = []\n",
        "    if ((len(df_copied.iloc[row][-1])) > 1):\n",
        "        pos = []\n",
        "        neg = []\n",
        "        for emotion in (df_copied.iloc[row][-1]):\n",
        "            if (emotion in positive_emotions):\n",
        "                pos.append(emotion)\n",
        "            else:\n",
        "                neg.append(emotion)\n",
        "        if (len(pos) == len(neg)):\n",
        "            c1 = 0\n",
        "            c2 = 0\n",
        "            c3 = 0\n",
        "            c4 = 0\n",
        "            for i in range (len(pos)):\n",
        "                if (pos[i] in p1):\n",
        "                    c1 = c1 + 1\n",
        "                elif (pos[i] in p2):\n",
        "                    c2 = c2 + 1\n",
        "                elif (pos[i] in n1):\n",
        "                    c3 = c3 + 1\n",
        "                else:\n",
        "                    c4 = c4 + 1\n",
        "            max_val = max(c1, c2, c3, c4)\n",
        "            if (max_val == c1):\n",
        "                value = 'happy'\n",
        "            elif (max_val == c2):\n",
        "                value = 'excited'\n",
        "            if (max_val == c3):\n",
        "                value = 'anxious'\n",
        "            else:\n",
        "                value  = 'angry'\n",
        "            df_copied.iat[row,-1] = [value]\n",
        "        elif (len(pos) > len(neg)):\n",
        "            c1 = 0\n",
        "            c2 = 0\n",
        "            for i in range (len(pos)):\n",
        "                if (pos[i] in p1):\n",
        "                    c1 = c1 + 1\n",
        "                else:\n",
        "                    c2 = c2 + 1\n",
        "            if (c1 > c2):\n",
        "                value = 'happy'\n",
        "            else:\n",
        "                value  = 'excited'\n",
        "            df_copied.iat[row,-1] = [value]\n",
        "        else:\n",
        "            c1 = 0\n",
        "            c2 = 0\n",
        "            for i in range (len(neg)):\n",
        "                if (neg[i] in n1):\n",
        "                    c1 = c1 + 1\n",
        "                else:\n",
        "                    c2 = c2 + 1\n",
        "            if (c1 > c2):\n",
        "                value = 'anxious'\n",
        "            else:\n",
        "                value  = 'angry'\n",
        "            df_copied.iat[row,-1] = [value]\n",
        "\n",
        "    if (set(df_copied.iloc[row][-1]).issubset(p1)):\n",
        "        df_copied.iat[row,-1] = 'happy'\n",
        "    elif (set(df_copied.iloc[row][-1]).issubset(p2)):\n",
        "        df_copied.iat[row,-1] = 'excited'\n",
        "    elif (set(df_copied.iloc[row][-1]).issubset(n1)):\n",
        "        df_copied.iat[row,-1] = 'anxious'\n",
        "    else:\n",
        "        df_copied.iat[row,-1] = 'angry'\n",
        "df_copied.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:56.22419Z",
          "iopub.status.busy": "2023-12-01T02:47:56.223927Z",
          "iopub.status.idle": "2023-12-01T02:47:56.230979Z",
          "shell.execute_reply": "2023-12-01T02:47:56.229964Z",
          "shell.execute_reply.started": "2023-12-01T02:47:56.224167Z"
        },
        "id": "ZQUp2f96GhU4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_copied['Emotions Felt'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:56.232685Z",
          "iopub.status.busy": "2023-12-01T02:47:56.232332Z",
          "iopub.status.idle": "2023-12-01T02:47:56.532052Z",
          "shell.execute_reply": "2023-12-01T02:47:56.530977Z",
          "shell.execute_reply.started": "2023-12-01T02:47:56.232657Z"
        },
        "id": "ewiAuJZiGhU4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#864 entries in last column which have more than one entry in the emotions list\n",
        "import random\n",
        "for row in range (0, len(df2)):\n",
        "    #topic_list = []\n",
        "    index = 0\n",
        "    if ((len(df2.iloc[row][-1])) > 1):\n",
        "        index = random.randrange(len(df2.iloc[row][-1]))\n",
        "    df2.iat[row,-1] = (df2.iloc[row][-1])[index]\n",
        "df2.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:56.533757Z",
          "iopub.status.busy": "2023-12-01T02:47:56.533364Z",
          "iopub.status.idle": "2023-12-01T02:47:56.547499Z",
          "shell.execute_reply": "2023-12-01T02:47:56.5464Z",
          "shell.execute_reply.started": "2023-12-01T02:47:56.533712Z"
        },
        "id": "v6WMey00GhU4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_copied.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:56.549209Z",
          "iopub.status.busy": "2023-12-01T02:47:56.548906Z",
          "iopub.status.idle": "2023-12-01T02:47:56.84746Z",
          "shell.execute_reply": "2023-12-01T02:47:56.846448Z",
          "shell.execute_reply.started": "2023-12-01T02:47:56.549182Z"
        },
        "id": "6Htm-vEGGhU5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#importing libraries and modules\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:56.848996Z",
          "iopub.status.busy": "2023-12-01T02:47:56.848681Z",
          "iopub.status.idle": "2023-12-01T02:47:56.857405Z",
          "shell.execute_reply": "2023-12-01T02:47:56.856259Z",
          "shell.execute_reply.started": "2023-12-01T02:47:56.84897Z"
        },
        "id": "KWR_lcNGGhU5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(df2.iloc[:,6:7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:56.858913Z",
          "iopub.status.busy": "2023-12-01T02:47:56.858594Z",
          "iopub.status.idle": "2023-12-01T02:47:56.869916Z",
          "shell.execute_reply": "2023-12-01T02:47:56.868883Z",
          "shell.execute_reply.started": "2023-12-01T02:47:56.858887Z"
        },
        "id": "SIA9ALnQGhU5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(df_copied.iloc[:,6:7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:56.871325Z",
          "iopub.status.busy": "2023-12-01T02:47:56.87106Z",
          "iopub.status.idle": "2023-12-01T02:47:56.88986Z",
          "shell.execute_reply": "2023-12-01T02:47:56.888772Z",
          "shell.execute_reply.started": "2023-12-01T02:47:56.871302Z"
        },
        "id": "cWOW_BZjGhU5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print((df_copied.iloc[:,6:7]).value_counts()['happy'])\n",
        "print((df_copied.iloc[:,6:7]).value_counts()['angry'])\n",
        "print((df_copied.iloc[:,6:7]).value_counts()['excited'])\n",
        "print((df_copied.iloc[:,6:7]).value_counts()['anxious'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:56.891393Z",
          "iopub.status.busy": "2023-12-01T02:47:56.891128Z",
          "iopub.status.idle": "2023-12-01T02:47:56.896456Z",
          "shell.execute_reply": "2023-12-01T02:47:56.895174Z",
          "shell.execute_reply.started": "2023-12-01T02:47:56.891368Z"
        },
        "id": "lNjVdo1yGhU5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "dfCOPY2 = df_copied.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:56.898751Z",
          "iopub.status.busy": "2023-12-01T02:47:56.898336Z",
          "iopub.status.idle": "2023-12-01T02:47:56.910274Z",
          "shell.execute_reply": "2023-12-01T02:47:56.909313Z",
          "shell.execute_reply.started": "2023-12-01T02:47:56.8987Z"
        },
        "id": "7sLcfIYzGhU5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_copied['Emotions Felt'] = df_copied['Emotions Felt'].replace('happy',0)\n",
        "df_copied['Emotions Felt'] = df_copied['Emotions Felt'].replace('excited',1)\n",
        "df_copied['Emotions Felt'] = df_copied['Emotions Felt'].replace('angry',2)\n",
        "df_copied['Emotions Felt'] = df_copied['Emotions Felt'].replace('anxious',3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:56.912107Z",
          "iopub.status.busy": "2023-12-01T02:47:56.91136Z",
          "iopub.status.idle": "2023-12-01T02:47:56.93644Z",
          "shell.execute_reply": "2023-12-01T02:47:56.935266Z",
          "shell.execute_reply.started": "2023-12-01T02:47:56.912078Z"
        },
        "id": "gBTv3xClGhU6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_copied.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:56.938579Z",
          "iopub.status.busy": "2023-12-01T02:47:56.937941Z",
          "iopub.status.idle": "2023-12-01T02:47:57.849206Z",
          "shell.execute_reply": "2023-12-01T02:47:57.847826Z",
          "shell.execute_reply.started": "2023-12-01T02:47:56.93854Z"
        },
        "id": "CUB_VR8ZGhU6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# example of oversampling a multi-class classification dataset\n",
        "from pandas import read_csv\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# define the dataset location\n",
        "# split into input and output elements\n",
        "X, y = df_copied.iloc[:,1:5], df_copied.iloc[:,6:7]\n",
        "# label encode the target variable\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "# transform the dataset\n",
        "#oversample = SMOTE()\n",
        "strategy = {0:3000, 1:3000, 2:3000, 3:3000}\n",
        "oversample = SMOTE(sampling_strategy=strategy)\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "# summarize distribution\n",
        "counter = Counter(y)\n",
        "for k,v in counter.items():\n",
        "    per = v / len(y) * 100\n",
        "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
        "# plot the distribution\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTdIVxfJGhU7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:57.85254Z",
          "iopub.status.busy": "2023-12-01T02:47:57.851673Z",
          "iopub.status.idle": "2023-12-01T02:47:57.861156Z",
          "shell.execute_reply": "2023-12-01T02:47:57.859763Z",
          "shell.execute_reply.started": "2023-12-01T02:47:57.85249Z"
        },
        "id": "3cXAM8_PGhU7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "counter.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:47:57.86414Z",
          "iopub.status.busy": "2023-12-01T02:47:57.863452Z",
          "iopub.status.idle": "2023-12-01T02:47:57.872209Z",
          "shell.execute_reply": "2023-12-01T02:47:57.870998Z",
          "shell.execute_reply.started": "2023-12-01T02:47:57.864105Z"
        },
        "id": "ryCTMgYXGhU8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3VAnT_LGhU8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:49:42.437677Z",
          "iopub.status.busy": "2023-12-01T02:49:42.436736Z",
          "iopub.status.idle": "2023-12-01T02:49:45.102824Z",
          "shell.execute_reply": "2023-12-01T02:49:45.101684Z",
          "shell.execute_reply.started": "2023-12-01T02:49:42.437634Z"
        },
        "id": "z3e_bMNDGhU8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#ON DF_COPIED\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier #latest run took 1 hour 9min to run\n",
        "from sklearn import metrics\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "rfc = RandomForestClassifier(n_estimators = 150)\n",
        "rfc.fit(X_train, y_train)\n",
        "y_pred_combo = rfc.predict(X_test)\n",
        "acc = metrics.accuracy_score(y_test, y_pred_combo)\n",
        "print(acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:49:49.663285Z",
          "iopub.status.busy": "2023-12-01T02:49:49.662878Z",
          "iopub.status.idle": "2023-12-01T02:49:49.70213Z",
          "shell.execute_reply": "2023-12-01T02:49:49.700918Z",
          "shell.execute_reply.started": "2023-12-01T02:49:49.663253Z"
        },
        "id": "CWDj7J98GhU8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#STEPS (don't run this piece of code)\n",
        "#Need to take the test + classification of emotion topic\n",
        "   # if there are multiple emotions topics, pick one at random?\n",
        "# Extract scores out of it (emotion score)\n",
        "#input it into the model with scores + topic for a final prediction\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "import string\n",
        "from textblob import TextBlob\n",
        "\n",
        "\n",
        "list_pos = []\n",
        "list_neg = []\n",
        "list_neu = []\n",
        "list_compound = []\n",
        "\n",
        "s1 = \"Today was a very hard day for me because 3 days ago I lost my dad forever. And then 3 days later my mom is admitted into the hospital. My two biggest supporters are going away from me in just a few days\"\n",
        "s2 = \"Two days ago, I was sitting in my living room. And it was raining. I personally don't like rain because when it rains everything gets wet and I hate looking at wet things. Also, a clean freak. So like when it rains my family members come from outside and they have dirt in their shoes and make the whole house dirty.\"\n",
        "s3 = \"Wow! I just landed my first internship today! Yay! I had a call with the recruiter and we finalized some details. I can't believe it!\"\n",
        "s4 = \"Tomorrow is my mom's birthday and I planned a surprise party for her. I bought her favorite cake, snacks, and invited close friends and family! I can't wait to see her expression!\"\n",
        "s5 = \"I am so stressed. I have three exams, 2 essays, one project, and a club proposal to submit all by the end of this week.\"\n",
        "s6 = \"Today was a very hard day for me because I was really feeling homesick, and I was missing my family and friends. I miss all our times together.\"\n",
        "s7 = \"It is so frustrating that I have not received the amazon package I ordered which had the gift for my friend's birthday. I have been waiting for weeks and it has still not arrived!\"\n",
        "s8 = \"I forgot my friend's birthday, and I feel really bad now. How could I do this?\"\n",
        "s9 = \"I lost my car keys, and I have been searching for hours and I still can't find them. I hate this!\"\n",
        "\n",
        "#also has a spell checker to account for certain spelling mistakes: ex. releeived and dissappointing\n",
        "s10 = \"I got so much work done today, and I feel really relieeved so now I don't have to worry about much for some time.\"\n",
        "s11 = \"I went for a walk with a friend to a boba shop, but it was closed, so that was dissappointing. Oh well...maybe next time.\"\n",
        "\n",
        "example_sent = s3\n",
        "example_sent = example_sent.replace(r'.', '')\n",
        "example_sent = example_sent.replace(r',', '')\n",
        "example_sent = example_sent.replace(r'!', '')\n",
        "example_sent = example_sent.replace(r';', '')\n",
        "example_sent = example_sent.replace(r'?', '')\n",
        "example_sent = example_sent.replace(r'(', '')\n",
        "example_sent = example_sent.replace(r')', '')\n",
        "example_sent = example_sent.replace(r\"'\", '')\n",
        "\n",
        "#print(example_sent)\n",
        "\n",
        "#example_sent = example_sent.replace(r'[^\\w\\s]+,', '')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "list_contractions_common = {'arent', 'cant', 'couldnt', 'didnt', 'doesnt', 'hadnt', 'havent', 'shouldnt', 'wouldnt', 'youve','youre','wont','werent', 'weve','wed', 'theyre', 'Im', 'its'}\n",
        "stop_words.update(list_contractions_common)\n",
        "\n",
        "word_tokens = word_tokenize(example_sent)\n",
        "\n",
        "#print(word_tokens)\n",
        "# converts the words in word_tokens to lower case and then checks whether\n",
        "#they are present in stop_words or not\n",
        "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "#with no lower case conversion\n",
        "filtered_sentence = []\n",
        "\n",
        "\n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "\n",
        "filtered_sentence = ' '.join(filtered_sentence)\n",
        "#print(filtered_sentence)\n",
        "\n",
        "final_sentence = filtered_sentence\n",
        "#filtered_sentence = TextBlob(filtered_sentence)\n",
        "#filtered_sentence = str(filtered_sentence.correct())\n",
        "\n",
        "print(filtered_sentence)\n",
        "\n",
        "pos_score = (sia.polarity_scores(filtered_sentence))['pos']\n",
        "neg_score = (sia.polarity_scores(filtered_sentence))['neg']\n",
        "neutral_score = (sia.polarity_scores(filtered_sentence))['neu']\n",
        "compound_score = (sia.polarity_scores(filtered_sentence))['compound']\n",
        "\n",
        "\n",
        "#emotion_topic = \"work\"#topic entered by user, may have to implement an algorithm to pick a topic if multiple are entered\n",
        "#creating a list of the necessary important\n",
        "\n",
        "#lists = [pos_score, neg_score, neutral_score, compound_score]\n",
        "#a = lists.reshape(1, -1)\n",
        "#then you feed lists into the model to predict\n",
        "\n",
        "data = {'positive_score': [pos_score], 'negative_score': [neg_score], 'neutral_score': [neutral_score], 'compound_score': [compound_score]}\n",
        "\n",
        "# Create DataFrame\n",
        "df_unseen = pd.DataFrame(data)\n",
        "\n",
        "predicted_score = rfc.predict(df_unseen)\n",
        "#print(predicted_score)\n",
        "\n",
        "#because the classification metrics were numbers, I need to convert them back to emotions\n",
        "final_pred = \"\"\n",
        "if (compound_score < 0):\n",
        "    if (predicted_score == [2]):\n",
        "        final_pred = 'angry'\n",
        "    else:\n",
        "        final_pred = 'anxious/sad'\n",
        "elif (predicted_score == [0]):\n",
        "    final_pred = 'happy'\n",
        "elif (predicted_score == [1]):\n",
        "    final_pred = 'excited'\n",
        "elif (predicted_score == [2]):\n",
        "    final_pred = 'angry'\n",
        "else:\n",
        "    final_pred = 'anxious/sad'\n",
        "\n",
        "print(final_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4lFb_x3GhU9",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:48:01.505022Z",
          "iopub.status.busy": "2023-12-01T02:48:01.504531Z",
          "iopub.status.idle": "2023-12-01T02:48:01.518608Z",
          "shell.execute_reply": "2023-12-01T02:48:01.51746Z",
          "shell.execute_reply.started": "2023-12-01T02:48:01.504995Z"
        },
        "id": "7xThmsCGGhU9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uibgr_qaGhU-"
      },
      "source": [
        "#STEPS (don't run this piece of code)\n",
        "#Need to take the test + classification of emotion topic\n",
        "   # if there are multiple emotions topics, pick one at random?\n",
        "# Extract scores out of it (emotion score)\n",
        "#input it into the model with scores + topic for a final prediction\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "import string\n",
        "\n",
        "\n",
        "list_pos = []\n",
        "list_neg = []\n",
        "list_neu = []\n",
        "list_compound = []\n",
        "\n",
        "    \n",
        "example_sent = #sentence entered in the journal goes here\n",
        "example_sent = example_sent.replace(r'.', '')\n",
        "example_sent = example_sent.replace(r',', '')\n",
        "example_sent = example_sent.replace(r'!', '')\n",
        "example_sent = example_sent.replace(r';', '')\n",
        "example_sent = example_sent.replace(r'?', '')\n",
        "example_sent = example_sent.replace(r'(', '')\n",
        "example_sent = example_sent.replace(r')', '')\n",
        "example_sent = example_sent.replace(r\"'\", '')\n",
        "\n",
        "#example_sent = example_sent[0].replace(r'[^\\w\\s]+,', '')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "list_contractions_common = {'arent', 'cant', 'couldnt', 'didnt', 'doesnt', 'dont', 'hadnt', 'havent', 'shouldnt', 'wouldnt', 'youve','youre','wont','werent', 'weve','wed', 'theyre', 'Im'}\n",
        "stop_words.update(list_contractions_common)\n",
        "\n",
        "word_tokens = word_tokenize(example_sent)\n",
        "# converts the words in word_tokens to lower case and then checks whether\n",
        "#they are present in stop_words or not\n",
        "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "#with no lower case conversion\n",
        "filtered_sentence = []\n",
        "\n",
        "\n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "\n",
        "filtered_sentence = ' '.join(filtered_sentence)\n",
        "\n",
        "\n",
        "final_sentence = filtered_sentence\n",
        "\n",
        "pos_score = (sia.polarity_scores(filtered_sentence))['pos']\n",
        "neg_score = (sia.polarity_scores(filtered_sentence))['neg']\n",
        "neutral_score = (sia.polarity_scores(filtered_sentence))['neu']\n",
        "compound_score = (sia.polarity_scores(filtered_sentence))['compound']\n",
        "    \n",
        "emotion_topic = #topic entered by user, may have to implement an algorithm to pick a topic if multiple are entered\n",
        "#creating a list of the necessary important\n",
        "lists = [pos_score, neg_score, neutral_score, compound_score, emotion_topic]\n",
        "\n",
        "#then you feed lists into the model to predict\n",
        "predicted_score = rfc.predict(lists)\n",
        "\n",
        "#because the classification metrics were numbers, I need to convert them back to emotions\n",
        "final_pred = \"\"\n",
        "if (predicted_score == 0):\n",
        "    final_pred = 'happy'\n",
        "elif (predicted_score == 1):\n",
        "    final_pred = 'excited'\n",
        "elif (predicted_score == 2):\n",
        "    final_pred = 'angry'\n",
        "else:\n",
        "    final_pred = 'anxious'\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MonNMTmBGhVB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:48:01.520427Z",
          "iopub.status.busy": "2023-12-01T02:48:01.520012Z",
          "iopub.status.idle": "2023-12-01T02:48:05.067487Z",
          "shell.execute_reply": "2023-12-01T02:48:05.066416Z",
          "shell.execute_reply.started": "2023-12-01T02:48:01.520389Z"
        },
        "id": "lbwdmiuRGhVC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#ON DF_COPIED\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier #latest run took 1 hour 9min to run\n",
        "from sklearn import metrics\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "rfc = RandomForestClassifier(n_estimators = 200)\n",
        "rfc.fit(X_train, y_train)\n",
        "y_pred_combo = rfc.predict(X_test)\n",
        "acc = metrics.accuracy_score(y_test, y_pred_combo)\n",
        "print(acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-01T02:48:05.069762Z",
          "iopub.status.busy": "2023-12-01T02:48:05.06884Z",
          "iopub.status.idle": "2023-12-01T02:48:05.076191Z",
          "shell.execute_reply": "2023-12-01T02:48:05.074252Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.069732Z"
        },
        "id": "oDGsd0r8GhVD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(rfc.predict[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.077444Z",
          "iopub.status.idle": "2023-12-01T02:48:05.078203Z",
          "shell.execute_reply": "2023-12-01T02:48:05.078012Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.077985Z"
        },
        "id": "GDWiMHoyGhVD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "knn_combination_f = KNeighborsClassifier(n_neighbors = 4)\n",
        "knn_combination_f.fit(X_train, y_train)\n",
        "y_pred_combo_f = knn_combination_f.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, y_pred_combo_f))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.080078Z",
          "iopub.status.idle": "2023-12-01T02:48:05.080788Z",
          "shell.execute_reply": "2023-12-01T02:48:05.080562Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.080543Z"
        },
        "id": "ZTkudYaBGhVE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "nb2 = GaussianNB()\n",
        "nb2.fit(X_train, y_train)\n",
        "y_pred2 = nb2.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, y_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.081746Z",
          "iopub.status.idle": "2023-12-01T02:48:05.082106Z",
          "shell.execute_reply": "2023-12-01T02:48:05.081948Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.081931Z"
        },
        "id": "NWc8Cpk1GhVE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df3 = df2.copy()\n",
        "#happy = 1\n",
        "#sad = 0\n",
        "positive_labels = {\"calm\", \"excited\", \"happy\", \"nostalgic\", \"proud\", \"satisfied\", \"surprised\"}\n",
        "#ok_labels = []\n",
        "negative_labels = {\"afriad\", \"angry\", \"anxious\", \"ashamed\", \"awkward\", \"bored\",\"confused\", \"disgusted\", \"frustrated\", \"jealous\", \"sad\"}\n",
        "for row in range (0, len(df3)):\n",
        "    #topic_list = []\n",
        "    if ((df3.iloc[row][-1]) in positive_labels):\n",
        "        df3.iat[row,-1] = \"happy\"\n",
        "    else:\n",
        "        df3.iat[row,-1] = \"sad\"\n",
        "df3.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.08383Z",
          "iopub.status.idle": "2023-12-01T02:48:05.084188Z",
          "shell.execute_reply": "2023-12-01T02:48:05.084034Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.084015Z"
        },
        "id": "JMUqpb4lGhVE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#need to train one model to predict emotion topic\n",
        "#need to train another to predict emotion felt\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier #latest run took 1 hour 9min to run\n",
        "from sklearn import metrics\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df3.iloc[:,1:5], df3.iloc[:,6:7], test_size=0.3, random_state=100)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "rfc = RandomForestClassifier(n_estimators = 143)\n",
        "rfc.fit(X_train, y_train)\n",
        "y_pred_combo = rfc.predict(X_test)\n",
        "acc = metrics.accuracy_score(y_test, y_pred_combo)\n",
        "print(acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.085756Z",
          "iopub.status.idle": "2023-12-01T02:48:05.086305Z",
          "shell.execute_reply": "2023-12-01T02:48:05.086151Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.086132Z"
        },
        "id": "mCP7-7V3GhVE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#ON DF_COPIED\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier #latest run took 1 hour 9min to run\n",
        "from sklearn import metrics\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_copied.iloc[:,1:5], df_copied.iloc[:,6:7], test_size=0.3, random_state=100)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "rfc = RandomForestClassifier(n_estimators = 400)\n",
        "rfc.fit(X_train, y_train)\n",
        "y_pred_combo = rfc.predict(X_test)\n",
        "acc = metrics.accuracy_score(y_test, y_pred_combo)\n",
        "print(acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.087094Z",
          "iopub.status.idle": "2023-12-01T02:48:05.087841Z",
          "shell.execute_reply": "2023-12-01T02:48:05.087637Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.087613Z"
        },
        "id": "R5CrYWbVGhVF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "X_train, X_test, y_train, y_test = train_test_split(df3.iloc[:,1:5], df3.iloc[:,6:7], test_size=0.3, random_state=100)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "nb2 = GaussianNB()\n",
        "nb2.fit(X_train, y_train)\n",
        "y_pred2 = nb2.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, y_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.089142Z",
          "iopub.status.idle": "2023-12-01T02:48:05.089889Z",
          "shell.execute_reply": "2023-12-01T02:48:05.089671Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.089647Z"
        },
        "id": "sCr-vA_nGhVF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#ON DF_COPIED\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_copied.iloc[:,1:5], df_copied.iloc[:,6:7], test_size=0.3, random_state=100)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "nb2 = GaussianNB()\n",
        "nb2.fit(X_train, y_train)\n",
        "y_pred2 = nb2.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, y_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.091176Z",
          "iopub.status.idle": "2023-12-01T02:48:05.091524Z",
          "shell.execute_reply": "2023-12-01T02:48:05.091374Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.091357Z"
        },
        "id": "8dzCvqP5GhVF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "max = 0\n",
        "max_random_state = 0\n",
        "for i in range (200):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df3.iloc[:,1:5], df3['Emotions Felt'], test_size=0.3, random_state=i)\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    nb2 = GaussianNB()\n",
        "    nb2.fit(X_train, y_train)\n",
        "    y_pred2 = nb2.predict(X_test)\n",
        "    if (metrics.accuracy_score(y_test, y_pred2) > max):\n",
        "        max = metrics.accuracy_score(y_test, y_pred2)\n",
        "        max_random_state = i\n",
        "print(max)\n",
        "print(max_random_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.09311Z",
          "iopub.status.idle": "2023-12-01T02:48:05.093462Z",
          "shell.execute_reply": "2023-12-01T02:48:05.09331Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.093293Z"
        },
        "id": "vU9yd7F5GhVG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "X_train, X_test, y_train, y_test = train_test_split(df3.iloc[:,1:5], df3.iloc[:,6:7], test_size=0.3, random_state=30)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "logreg = LogisticRegression(solver = 'liblinear', random_state = 0)\n",
        "logreg.fit(X_train, y_train)\n",
        "pred = logreg.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.094689Z",
          "iopub.status.idle": "2023-12-01T02:48:05.095079Z",
          "shell.execute_reply": "2023-12-01T02:48:05.094918Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.0949Z"
        },
        "id": "TwzBYDaQGhVG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "max = 0\n",
        "max_random_state = 0\n",
        "\n",
        "for i in range (200):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df3.iloc[:,1:5], df3['Emotions Felt'], test_size=0.3, random_state=i)\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    logreg = LogisticRegression(solver = 'liblinear', random_state = 0)\n",
        "    logreg.fit(X_train, y_train)\n",
        "    pred = logreg.predict(X_test)\n",
        "\n",
        "    if (metrics.accuracy_score(y_test, pred) > max):\n",
        "        max = metrics.accuracy_score(y_test, pred)\n",
        "        max_random_state = i\n",
        "\n",
        "print(max)\n",
        "print(max_random_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.096472Z",
          "iopub.status.idle": "2023-12-01T02:48:05.096855Z",
          "shell.execute_reply": "2023-12-01T02:48:05.096674Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.096657Z"
        },
        "id": "1N0F0GnNGhVG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(df3.iloc[:,1:5], df3.iloc[:,6:7], test_size=0.3, random_state=20)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "knn_combination_f = KNeighborsClassifier(n_neighbors = 6)\n",
        "knn_combination_f.fit(X_train, y_train)\n",
        "y_pred_combo_f = knn_combination_f.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, y_pred_combo_f))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.09827Z",
          "iopub.status.idle": "2023-12-01T02:48:05.098642Z",
          "shell.execute_reply": "2023-12-01T02:48:05.098484Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.098466Z"
        },
        "id": "2_Ke3Aq5GhVH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#ON DF_COPIED\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_copied.iloc[:,1:5], df_copied.iloc[:,6:7], test_size=0.3, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "knn_combination_f = KNeighborsClassifier(n_neighbors = 10)\n",
        "knn_combination_f.fit(X_train, y_train)\n",
        "y_pred_combo_f = knn_combination_f.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, y_pred_combo_f))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.100482Z",
          "iopub.status.idle": "2023-12-01T02:48:05.100874Z",
          "shell.execute_reply": "2023-12-01T02:48:05.100688Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.100671Z"
        },
        "id": "Pu1PPaMXGhVH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "max = 0\n",
        "max_random_state = 0\n",
        "\n",
        "for i in range (200):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df3.iloc[:,1:5], df3['Emotions Felt'], test_size=0.3, random_state= i)\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    knn_combination_f = KNeighborsClassifier(n_neighbors = 4)\n",
        "    knn_combination_f.fit(X_train, y_train)\n",
        "    y_pred_combo_f = knn_combination_f.predict(X_test)\n",
        "    if (metrics.accuracy_score(y_test, y_pred_combo_f) > max):\n",
        "        max = metrics.accuracy_score(y_test, y_pred_combo_f)\n",
        "        max_random_state = i\n",
        "print(max)\n",
        "print(max_random_state)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.101936Z",
          "iopub.status.idle": "2023-12-01T02:48:05.102291Z",
          "shell.execute_reply": "2023-12-01T02:48:05.102138Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.102121Z"
        },
        "id": "803gKrPNGhVH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(accuracy_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.10457Z",
          "iopub.status.idle": "2023-12-01T02:48:05.104941Z",
          "shell.execute_reply": "2023-12-01T02:48:05.104784Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.104762Z"
        },
        "id": "gmmOtQUuGhVI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# #ITERATIVE HYPERPARAMTER TUNING\n",
        "# from sklearn.ensemble import RandomForestClassifier #latest run took 1 hour 9min to run\n",
        "# accuracy_array = []\n",
        "# max_accuracy = 0\n",
        "# random_state_max = 0\n",
        "# max_estimators = 0\n",
        "# for i in range (1,100):\n",
        "#     X_train, X_test, y_train, y_test = train_test_split(df3.iloc[:,1:5], df3['Emotions Felt'], test_size=0.3, random_state=i)\n",
        "#     scaler = StandardScaler()\n",
        "#     scaler.fit(X_train)\n",
        "#     X_train = scaler.transform(X_train)\n",
        "#     X_test = scaler.transform(X_test)\n",
        "#     for x in range (20, 300):\n",
        "#         rfc = RandomForestClassifier(n_estimators = x)\n",
        "#         rfc.fit(X_train, y_train)\n",
        "#         y_pred_combo = rfc.predict(X_test)\n",
        "#         acc = metrics.accuracy_score(y_test, y_pred_combo)\n",
        "#         if (acc > max_accuracy):\n",
        "#             random_state_max = i\n",
        "#             max_estimators = x\n",
        "#             max_accuracy = acc\n",
        "#         accuracy_array.append(acc)\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(10,6))\n",
        "# plt.plot(range(1,17821),accuracy_array,color='blue', linestyle='dashed',marker='o',markerfacecolor='red', markersize=10)\n",
        "# plt.title('Model Accuracy vs n-estimators vs random-state')\n",
        "# plt.xlabel('n-estimators')\n",
        "# plt.ylabel('Model Accuracy')\n",
        "# print(\"Maximum accuracy\",max(accuracy_array),\"at N estimators =\",max_estimators, \"at random_state =\", random_state_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.10612Z",
          "iopub.status.idle": "2023-12-01T02:48:05.106472Z",
          "shell.execute_reply": "2023-12-01T02:48:05.106319Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.106302Z"
        },
        "id": "gr0OnkrbGhVI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#need to train one model to predict emotion topic\n",
        "#need to train another to predict emotion felt\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier #latest run took 1 hour 9min to run\n",
        "from sklearn import metrics\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df2.iloc[:,1:5], df2.iloc[:,6:7], test_size=0.3, random_state=10)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "rfc = RandomForestClassifier(n_estimators = 50)\n",
        "rfc.fit(X_train, y_train)\n",
        "y_pred_combo = rfc.predict(X_test)\n",
        "acc = metrics.accuracy_score(y_test, y_pred_combo)\n",
        "print(acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.108353Z",
          "iopub.status.idle": "2023-12-01T02:48:05.109024Z",
          "shell.execute_reply": "2023-12-01T02:48:05.108841Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.108821Z"
        },
        "id": "1pNPfZaOGhVI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#you have to take in an incoming stream of text, calculate all the score metrics, and then feed it into the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.11019Z",
          "iopub.status.idle": "2023-12-01T02:48:05.110557Z",
          "shell.execute_reply": "2023-12-01T02:48:05.110399Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.110381Z"
        },
        "id": "05Ej0DkqGhVJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# cosine distance\n",
        "# pick the most relevant emotion compared to the list of emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.111788Z",
          "iopub.status.idle": "2023-12-01T02:48:05.112151Z",
          "shell.execute_reply": "2023-12-01T02:48:05.111996Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.111971Z"
        },
        "id": "KeAc4WBZGhVJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/kaggle/input/journal-entries-with-labelled-emotions/data.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.113582Z",
          "iopub.status.idle": "2023-12-01T02:48:05.113951Z",
          "shell.execute_reply": "2023-12-01T02:48:05.113795Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.113778Z"
        },
        "id": "pUHlVb-HGhVJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data = data.iloc[:, 0:1]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.115205Z",
          "iopub.status.idle": "2023-12-01T02:48:05.115571Z",
          "shell.execute_reply": "2023-12-01T02:48:05.115401Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.115384Z"
        },
        "id": "O_1OZ_3KGhVJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.116752Z",
          "iopub.status.idle": "2023-12-01T02:48:05.117099Z",
          "shell.execute_reply": "2023-12-01T02:48:05.116947Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.116931Z"
        },
        "id": "qag_4BLIGhVK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load the regular expression library\n",
        "import re\n",
        "# Remove punctuation\n",
        "data['Answer'] = \\\n",
        "data['Answer'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
        "# Convert the titles to lowercase\n",
        "data['Answer'] = \\\n",
        "data['Answer'].map(lambda x: x.lower())\n",
        "# Print out the first rows of papers\n",
        "data['Answer'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.118019Z",
          "iopub.status.idle": "2023-12-01T02:48:05.118364Z",
          "shell.execute_reply": "2023-12-01T02:48:05.118214Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.118195Z"
        },
        "id": "0dwkUmG4GhVK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import the wordcloud library\n",
        "from wordcloud import WordCloud\n",
        "# Join the different processed titles together.\n",
        "long_string = ','.join(list(data['Answer'].values))\n",
        "# Create a WordCloud object\n",
        "wordcloud = WordCloud(background_color=\"white\", max_words=5000, contour_width=3, contour_color='steelblue')\n",
        "# Generate a word cloud\n",
        "wordcloud.generate(long_string)\n",
        "# Visualize the word cloud\n",
        "wordcloud.to_image()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.11939Z",
          "iopub.status.idle": "2023-12-01T02:48:05.119758Z",
          "shell.execute_reply": "2023-12-01T02:48:05.119586Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.119569Z"
        },
        "id": "9uCB1WavGhVK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        # deacc=True removes punctuations\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc))\n",
        "             if word not in stop_words] for doc in texts]\n",
        "data1 = data.Answer.values.tolist()\n",
        "data_words = list(sent_to_words(data1))\n",
        "# remove stop words\n",
        "data_words = remove_stopwords(data_words)\n",
        "\n",
        "#print(data_words[0])\n",
        "print(data_words[:1][0][:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHsk1E8bGhVK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.121562Z",
          "iopub.status.idle": "2023-12-01T02:48:05.121934Z",
          "shell.execute_reply": "2023-12-01T02:48:05.121776Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.121757Z"
        },
        "id": "lNOwWVPnGhVL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#how often the word appears in the text\n",
        "\n",
        "import gensim.corpora as corpora\n",
        "# Create Dictionary\n",
        "print(data_words[0])\n",
        "id2word = corpora.Dictionary([data_words[0]])\n",
        "\n",
        "print(id2word)\n",
        "\n",
        "# Create Corpus\n",
        "\n",
        "\n",
        "texts = data_words[0]\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow([text]) for text in texts]\n",
        "# View\n",
        "print(corpus)\n",
        "#print(corpus[:1][0][:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.12329Z",
          "iopub.status.idle": "2023-12-01T02:48:05.123646Z",
          "shell.execute_reply": "2023-12-01T02:48:05.123493Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.123469Z"
        },
        "id": "cQEgg1muGhVL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "# number of topics\n",
        "num_topics = 10\n",
        "# Build LDA model\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=num_topics)\n",
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T02:48:05.125277Z",
          "iopub.status.idle": "2023-12-01T02:48:05.125651Z",
          "shell.execute_reply": "2023-12-01T02:48:05.125491Z",
          "shell.execute_reply.started": "2023-12-01T02:48:05.125473Z"
        },
        "id": "uy1HIluRGhVM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#compile all the keywords together in a set for the 10 topics, and just check if each topic (from dataset) is in it, and if not ...."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis Project - P-reset",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 1651065,
          "sourceId": 2709980,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30558,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
