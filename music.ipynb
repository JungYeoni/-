{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1f1ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: torchvision in c:\\programdata\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: torchaudio in c:\\programdata\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.6.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (0.8.3)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2.11.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied: numpy<2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.19.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch) (1.1.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from networkx->torch) (4.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: seaborn in c:\\programdata\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.19.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.50.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# PyTorch 및 필요한 라이브러리 설치\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install scikit-learn matplotlib seaborn pandas numpy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e312e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 사용 디바이스: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "import requests\n",
    "from io import StringIO\n",
    "import json\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# CUDA 사용 가능 여부 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\" 사용 디바이스: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35e75d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 데이터셋이 이미 존재합니다.\n",
      "데이터셋 파일: spotify_songs.csv\n"
     ]
    }
   ],
   "source": [
    "# Spotify 데이터셋 다운로드\n",
    "# ========================================\n",
    "\n",
    "def download_spotify_dataset():\n",
    "    \"\"\"Spotify 데이터셋 다운로드\"\"\"\n",
    "    url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv\"\n",
    "    filename = \"spotify_songs.csv\"\n",
    "    \n",
    "    if not os.path.exists(filename):\n",
    "        print(\" Spotify 데이터셋을 다운로드 중...\")\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(response.text)\n",
    "            print(\" 다운로드 완료!\")\n",
    "        except Exception as e:\n",
    "            print(f\" 다운로드 실패: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\" 데이터셋이 이미 존재합니다.\")\n",
    "    \n",
    "    return filename\n",
    "\n",
    "# 데이터셋 다운로드 실행\n",
    "dataset_file = download_spotify_dataset()\n",
    "print(f\"데이터셋 파일: {dataset_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d47aee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 신경망 모델 정의 완료!\n"
     ]
    }
   ],
   "source": [
    "#  PyTorch 신경망 모델 정의\n",
    "# ========================================\n",
    "\n",
    "class MusicEmotionClassifier(nn.Module):\n",
    "    \"\"\"음악 감정 분류를 위한 신경망 모델\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes=[256, 128, 64], num_classes=5, dropout_rate=0.3):\n",
    "        super(MusicEmotionClassifier, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        for i, hidden_size in enumerate(hidden_sizes):\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate if i < len(hidden_sizes)-1 else dropout_rate/2)\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # 출력층\n",
    "        layers.extend([\n",
    "            nn.Linear(prev_size, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        ])\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class ValencePredictor(nn.Module):\n",
    "    \"\"\"Valence 값 예측을 위한 회귀 모델\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes=[128, 64, 32], dropout_rate=0.2):\n",
    "        super(ValencePredictor, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # 출력층 (0-1 범위)\n",
    "        layers.extend([\n",
    "            nn.Linear(prev_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        ])\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "print(\" 신경망 모델 정의 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba61cc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Spotify 음악 감정 추천 시스템 초기화 완료!\n",
      " 감정 카테고리: 5개\n",
      " 감정 매핑: 30개\n",
      "\n",
      " 시스템 객체 생성 완료!\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "#  음악 감정 분석 및 추천 시스템 (1부)\n",
    "# ========================================\n",
    "\n",
    "class SpotifyEmotionRecommendationSystem:\n",
    "    def __init__(self, random_seed=42):\n",
    "        \"\"\"시스템 초기화\"\"\"\n",
    "        \n",
    "        # 시드 설정\n",
    "        torch.manual_seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        \n",
    "        self.device = device\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.df = None\n",
    "        self.emotion_classifier = None\n",
    "        self.valence_predictor = None\n",
    "        \n",
    "        # 감정 카테고리 정의 (valence 기반)\n",
    "        self.emotion_categories = {\n",
    "            'very_sad': {'valence_range': (0.0, 0.2), 'energy_weight': 0.3, 'label': '매우 슬픔'},\n",
    "            'sad': {'valence_range': (0.2, 0.4), 'energy_weight': 0.4, 'label': '슬픔'},\n",
    "            'calm': {'valence_range': (0.4, 0.6), 'energy_weight': 0.5, 'label': '평온'},\n",
    "            'happy': {'valence_range': (0.6, 0.8), 'energy_weight': 0.6, 'label': '행복'},\n",
    "            'very_happy': {'valence_range': (0.8, 1.0), 'energy_weight': 0.7, 'label': '매우 행복'}\n",
    "        }\n",
    "        \n",
    "        # 세분화된 감정 매핑 (일기 감정라벨과 연동 준비)\n",
    "        self.emotion_mapping = {\n",
    "            # 매우 부정적 감정\n",
    "            '절망': 'very_sad', '우울': 'very_sad', '좌절': 'very_sad', \n",
    "            '비참': 'very_sad', '암울': 'very_sad',\n",
    "            \n",
    "            # 부정적 감정\n",
    "            '슬픔': 'sad', '외로움': 'sad', '그리움': 'sad', \n",
    "            '아쉬움': 'sad', '후회': 'sad', '실망': 'sad',\n",
    "            \n",
    "            # 중립적 감정\n",
    "            '평온': 'calm', '차분': 'calm', '안정': 'calm', '보통': 'calm',\n",
    "            '무난': 'calm', '여유': 'calm', '편안': 'calm',\n",
    "            \n",
    "            # 긍정적 감정\n",
    "            '기쁨': 'happy', '행복': 'happy', '즐거움': 'happy', \n",
    "            '만족': 'happy', '고마움': 'happy', '사랑': 'happy',\n",
    "            \n",
    "            # 매우 긍정적 감정\n",
    "            '환희': 'very_happy', '황홀': 'very_happy', '열광': 'very_happy',\n",
    "            '신남': 'very_happy', '흥분': 'very_happy', '설렘': 'very_happy'\n",
    "        }\n",
    "        \n",
    "        print(\" Spotify 음악 감정 추천 시스템 초기화 완료!\")\n",
    "        print(f\" 감정 카테고리: {len(self.emotion_categories)}개\")\n",
    "        print(f\" 감정 매핑: {len(self.emotion_mapping)}개\")\n",
    "\n",
    "# 시스템 초기화 테스트\n",
    "system = SpotifyEmotionRecommendationSystem()\n",
    "print(\"\\n 시스템 객체 생성 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bf5ec01",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-12b4ab87e578>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-26-12b4ab87e578>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    ========================================\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " ========================================\n",
    "#  데이터 로드 및 전처리 메서드 추가\n",
    "# ========================================\n",
    "\n",
    "def load_and_preprocess_data(self, file_path=None):\n",
    "    \"\"\"데이터 로드 및 전처리\"\"\"\n",
    "    try:\n",
    "        # 파일 경로가 없으면 다운로드\n",
    "        if file_path is None:\n",
    "            file_path = download_spotify_dataset()\n",
    "            if file_path is None:\n",
    "                return None\n",
    "        \n",
    "        print(\" 데이터 로드 중...\")\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        print(f\" 원본 데이터: {len(self.df):,} 곡\")\n",
    "        \n",
    "        # 필요한 컬럼 확인\n",
    "        required_cols = ['valence', 'energy', 'danceability', 'acousticness']\n",
    "        missing_cols = [col for col in required_cols if col not in self.df.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            print(f\" 필수 컬럼 누락: {missing_cols}\")\n",
    "            return None\n",
    "        \n",
    "        # 데이터 정리\n",
    "        print(\" 데이터 전처리 중...\")\n",
    "        \n",
    "        # 결측치 제거\n",
    "        original_len = len(self.df)\n",
    "        self.df = self.df.dropna(subset=required_cols)\n",
    "        print(f\" 결측치 제거: {original_len - len(self.df):,} 곡 제거\")\n",
    "        \n",
    "        # 이상치 제거 (0-1 범위 벗어난 값)\n",
    "        for col in ['valence', 'energy', 'danceability', 'acousticness']:\n",
    "            if col in self.df.columns:\n",
    "                before_len = len(self.df)\n",
    "                self.df = self.df[(self.df[col] >= 0) & (self.df[col] <= 1)]\n",
    "                if len(self.df) < before_len:\n",
    "                    print(f\" {col} 이상치 제거: {before_len - len(self.df)} 곡\")\n",
    "        \n",
    "        # 감정 라벨 생성\n",
    "        print(\" 감정 라벨 생성 중...\")\n",
    "        self.df['emotion_category'] = self.df.apply(self._classify_emotion, axis=1)\n",
    "        \n",
    "        # 감정별 분포 출력\n",
    "        print(\"\\n 감정별 분포:\")\n",
    "        emotion_counts = self.df['emotion_category'].value_counts()\n",
    "        for emotion, count in emotion_counts.items():\n",
    "            label = self.emotion_categories[emotion]['label']\n",
    "            print(f\"  {label} ({emotion}): {count:,}곡 ({count/len(self.df)*100:.1f}%)\")\n",
    "        \n",
    "        # 데이터 시각화\n",
    "        self._visualize_data_distribution()\n",
    "        \n",
    "        print(f\"\\n 전처리 완료: {len(self.df):,} 곡\")\n",
    "        return self.df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" 데이터 로드 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "def _classify_emotion(self, row):\n",
    "    \"\"\"valence와 energy 기반 감정 분류\"\"\"\n",
    "    valence = row['valence']\n",
    "    energy = row.get('energy', 0.5)  # 기본값\n",
    "    \n",
    "    # valence 기반 1차 분류\n",
    "    for emotion, config in self.emotion_categories.items():\n",
    "        v_min, v_max = config['valence_range']\n",
    "        if v_min <= valence < v_max:\n",
    "            # energy 가중치 적용한 최종 판단\n",
    "            energy_threshold = config['energy_weight']\n",
    "            if energy >= energy_threshold or emotion in ['very_sad', 'sad']:\n",
    "                return emotion\n",
    "    \n",
    "    # 기본값\n",
    "    return 'calm'\n",
    "\n",
    "# 클래스에 메서드 추가\n",
    "SpotifyEmotionRecommendationSystem.load_and_preprocess_data = load_and_preprocess_data\n",
    "SpotifyEmotionRecommendationSystem._classify_emotion = _classify_emotion\n",
    "\n",
    "print(\" 데이터 전처리 메서드 추가 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "287ef077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎵 통합 음악 감정 분류 및 추천 시스템\n",
    "# ========================================\n",
    "\n",
    "class MusicEmotionRecommendationSystem:\n",
    "    def __init__(self, random_seed=42):\n",
    "        \"\"\"음악 감정 분류 및 추천 시스템 초기화\"\"\"\n",
    "        \n",
    "        # 시드 설정\n",
    "        torch.manual_seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        \n",
    "        self.device = device\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.df = None\n",
    "        self.emotion_classifier = None\n",
    "        self.valence_regressor = None\n",
    "        \n",
    "        # 감정 카테고리 정의 (valence와 energy 기반)\n",
    "        self.emotion_categories = {\n",
    "            'sad': {'valence': (0.0, 0.3), 'energy': (0.0, 0.5)},\n",
    "            'calm': {'valence': (0.3, 0.7), 'energy': (0.0, 0.6)},\n",
    "            'happy': {'valence': (0.7, 1.0), 'energy': (0.5, 1.0)},\n",
    "            'angry': {'valence': (0.0, 0.4), 'energy': (0.7, 1.0)},\n",
    "            'energetic': {'valence': (0.6, 1.0), 'energy': (0.8, 1.0)}\n",
    "        }\n",
    "        \n",
    "        # 일기 감정 → 음악 감정 매핑\n",
    "        self.diary_to_music_emotion = {\n",
    "            # 긍정적 감정\n",
    "            '기쁨': 'happy', '행복': 'happy', '즐거움': 'happy', '만족': 'happy',\n",
    "            '사랑': 'happy', '고마움': 'happy', '희망': 'happy', '설렘': 'happy',\n",
    "            \n",
    "            # 활동적 감정\n",
    "            '신남': 'energetic', '활기': 'energetic', '흥분': 'energetic', \n",
    "            '에너지': 'energetic', '자신감': 'energetic', '의욕': 'energetic',\n",
    "            \n",
    "            # 부정적 감정\n",
    "            '슬픔': 'sad', '우울': 'sad', '눈물': 'sad', '외로움': 'sad',\n",
    "            '그리움': 'sad', '아쉬움': 'sad', '후회': 'sad', '실망': 'sad',\n",
    "            \n",
    "            # 분노 관련 감정\n",
    "            '화남': 'angry', '분노': 'angry', '짜증': 'angry', '화': 'angry',\n",
    "            '불만': 'angry', '스트레스': 'angry', '답답함': 'angry',\n",
    "            \n",
    "            # 평온한 감정\n",
    "            '평온': 'calm', '차분': 'calm', '안정': 'calm', '편안': 'calm',\n",
    "            '보통': 'calm', '그냥': 'calm', '무난': 'calm', '여유': 'calm',\n",
    "            '피곤': 'calm', '지침': 'calm'\n",
    "        }\n",
    "        \n",
    "        print(\"음악 감정 분류 및 추천 시스템 초기화 완료!\")\n",
    "    \n",
    "    def load_spotify_data(self, file_path):\n",
    "        \"\"\"Spotify 데이터셋 로드 및 전처리\"\"\"\n",
    "        try:\n",
    "            self.df = pd.read_csv(file_path)\n",
    "            print(f\" 데이터 로드 완료: {len(self.df):,} 곡\")\n",
    "            \n",
    "            # 데이터 정보 출력\n",
    "            print(f\" 데이터셋 컬럼: {list(self.df.columns)}\")\n",
    "            \n",
    "            # 필요한 컬럼 확인 및 매핑\n",
    "            column_mapping = {\n",
    "                'track_name': 'name',\n",
    "                'track_artist': 'artists',\n",
    "                'track_album_name': 'album',\n",
    "                'track_popularity': 'popularity'\n",
    "            }\n",
    "            \n",
    "            for old_col, new_col in column_mapping.items():\n",
    "                if old_col in self.df.columns and new_col not in self.df.columns:\n",
    "                    self.df[new_col] = self.df[old_col]\n",
    "            \n",
    "            # 필요한 오디오 특성 확인\n",
    "            audio_features = ['valence', 'energy', 'danceability', 'acousticness', \n",
    "                             'instrumentalness', 'liveness', 'speechiness']\n",
    "            missing_features = [f for f in audio_features if f not in self.df.columns]\n",
    "            \n",
    "            if missing_features:\n",
    "                print(f\" 누락된 오디오 특성: {missing_features}\")\n",
    "                return None\n",
    "            \n",
    "            # 결측치 처리\n",
    "            print(f\" 결측치 제거 전: {len(self.df):,} 곡\")\n",
    "            self.df = self.df.dropna(subset=audio_features)\n",
    "            print(f\" 결측치 제거 후: {len(self.df):,} 곡\")\n",
    "            \n",
    "            # valence와 energy 값 범위 확인 및 정규화\n",
    "            for feature in ['valence', 'energy']:\n",
    "                if self.df[feature].max() > 1:\n",
    "                    print(f\"⚠️ {feature} 값을 0-1 범위로 정규화합니다.\")\n",
    "                    self.df[feature] = self.df[feature] / self.df[feature].max()\n",
    "            \n",
    "            # 감정 라벨 생성\n",
    "            print(\" 감정 라벨 생성 중...\")\n",
    "            self.df['emotion_label'] = self.df.apply(\n",
    "                lambda row: self._classify_emotion_by_valence_energy(\n",
    "                    row['valence'], row['energy']\n",
    "                ), axis=1\n",
    "            )\n",
    "            \n",
    "            # 감정별 분포 출력\n",
    "            print(f\"\\n 감정별 분포:\")\n",
    "            emotion_counts = self.df['emotion_label'].value_counts()\n",
    "            for emotion, count in emotion_counts.items():\n",
    "                print(f\"  {emotion}: {count:,}곡 ({count/len(self.df)*100:.1f}%)\")\n",
    "            \n",
    "            # 데이터 시각화\n",
    "            self._visualize_emotion_distribution()\n",
    "            \n",
    "            return self.df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" 데이터 로드 실패: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _classify_emotion_by_valence_energy(self, valence, energy):\n",
    "        \"\"\"valence와 energy 값으로 감정 분류\"\"\"\n",
    "        for emotion, ranges in self.emotion_categories.items():\n",
    "            if (ranges['valence'][0] <= valence <= ranges['valence'][1] and \n",
    "                ranges['energy'][0] <= energy <= ranges['energy'][1]):\n",
    "                return emotion\n",
    "        return 'calm'  # 기본값\n",
    "    \n",
    "    def _visualize_emotion_distribution(self):\n",
    "        \"\"\"감정 분포 시각화\"\"\"\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # 1. 감정별 분포 파이차트\n",
    "        plt.subplot(1, 3, 1)\n",
    "        emotion_counts = self.df['emotion_label'].value_counts()\n",
    "        plt.pie(emotion_counts.values, labels=emotion_counts.index, autopct='%1.1f%%')\n",
    "        plt.title('감정별 곡 분포')\n",
    "        \n",
    "        # 2. Valence vs Energy 산점도\n",
    "        plt.subplot(1, 3, 2)\n",
    "        colors = {'sad': 'blue', 'calm': 'green', 'happy': 'yellow', \n",
    "                 'angry': 'red', 'energetic': 'orange'}\n",
    "        \n",
    "        for emotion in self.emotion_categories.keys():\n",
    "            emotion_data = self.df[self.df['emotion_label'] == emotion]\n",
    "            if len(emotion_data) > 0:\n",
    "                plt.scatter(emotion_data['valence'], emotion_data['energy'], \n",
    "                          c=colors.get(emotion, 'gray'), label=emotion, alpha=0.6, s=1)\n",
    "        \n",
    "        plt.xlabel('Valence')\n",
    "        plt.ylabel('Energy')\n",
    "        plt.title('Valence vs Energy by Emotion')\n",
    "        plt.legend()\n",
    "        \n",
    "        # 3. Valence 분포 히스토그램\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.hist(self.df['valence'], bins=30, alpha=0.7, edgecolor='black')\n",
    "        plt.xlabel('Valence')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Valence 분포')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def prepare_features_and_labels(self, for_regression=False):\n",
    "        \"\"\"모델 훈련을 위한 특성과 라벨 준비\"\"\"\n",
    "        if self.df is None:\n",
    "            print(\" 데이터를 먼저 로드해주세요.\")\n",
    "            return None, None\n",
    "        \n",
    "        # 오디오 특성 선택\n",
    "        if for_regression:\n",
    "            # 회귀용: valence 제외\n",
    "            audio_features = ['energy', 'danceability', 'acousticness', \n",
    "                             'instrumentalness', 'liveness', 'speechiness']\n",
    "            target = 'valence'\n",
    "        else:\n",
    "            # 분류용: 모든 특성 포함\n",
    "            audio_features = ['valence', 'energy', 'danceability', 'acousticness', \n",
    "                             'instrumentalness', 'liveness', 'speechiness']\n",
    "            target = 'emotion_label'\n",
    "        \n",
    "        # 실제 존재하는 특성만 선택\n",
    "        available_features = [f for f in audio_features if f in self.df.columns]\n",
    "        \n",
    "        if len(available_features) < 2:\n",
    "            print(f\" 충분한 오디오 특성이 없습니다. 사용 가능: {available_features}\")\n",
    "            return None, None\n",
    "        \n",
    "        print(f\" 사용할 특성: {available_features}\")\n",
    "        \n",
    "        # 특성 및 타겟 추출\n",
    "        X = self.df[available_features].values\n",
    "        \n",
    "        if for_regression:\n",
    "            y = self.df[target].values\n",
    "        else:\n",
    "            y = self.df[target].values\n",
    "            y = self.label_encoder.fit_transform(y)\n",
    "        \n",
    "        # 특성 정규화\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        return X_scaled, y\n",
    "    \n",
    "    def train_emotion_classifier(self, test_size=0.2, batch_size=256, epochs=50, lr=0.001):\n",
    "        \"\"\"감정 분류 모델 훈련\"\"\"\n",
    "        print(\" 감정 분류 모델 훈련 시작...\")\n",
    "        \n",
    "        X, y = self.prepare_features_and_labels(for_regression=False)\n",
    "        if X is None or y is None:\n",
    "            return False\n",
    "        \n",
    "        # 훈련/테스트 분할\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # PyTorch 텐서 변환\n",
    "        X_train_tensor = torch.FloatTensor(X_train).to(self.device)\n",
    "        y_train_tensor = torch.LongTensor(y_train).to(self.device)\n",
    "        X_test_tensor = torch.FloatTensor(X_test).to(self.device)\n",
    "        y_test_tensor = torch.LongTensor(y_test).to(self.device)\n",
    "        \n",
    "        # 데이터 로더\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # 모델 초기화\n",
    "        input_size = X.shape[1]\n",
    "        num_classes = len(self.label_encoder.classes_)\n",
    "        self.emotion_classifier = MusicEmotionNet(input_size, num_classes=num_classes).to(self.device)\n",
    "        \n",
    "        # 손실 함수 및 최적화기\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.emotion_classifier.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)\n",
    "        \n",
    "        # 훈련\n",
    "        train_losses, train_accuracies = [], []\n",
    "        \n",
    "        self.emotion_classifier.train()\n",
    "        for epoch in tqdm(range(epochs), desc=\"분류 모델 훈련\"):\n",
    "            epoch_loss, correct, total = 0, 0, 0\n",
    "            \n",
    "            for batch_X, batch_y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.emotion_classifier(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += batch_y.size(0)\n",
    "                correct += (predicted == batch_y).sum().item()\n",
    "            \n",
    "            avg_loss = epoch_loss / len(train_loader)\n",
    "            accuracy = 100 * correct / total\n",
    "            train_losses.append(avg_loss)\n",
    "            train_accuracies.append(accuracy)\n",
    "            scheduler.step(avg_loss)\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}] Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40da618a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 시각화 메서드 추가 완료!\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "#  데이터 시각화 메서드\n",
    "# ========================================\n",
    "\n",
    "def _visualize_data_distribution(self):\n",
    "    \"\"\"데이터 분포 시각화\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. 감정별 분포\n",
    "    emotion_counts = self.df['emotion_category'].value_counts()\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
    "    \n",
    "    axes[0,0].pie(emotion_counts.values, labels=[self.emotion_categories[e]['label'] for e in emotion_counts.index], \n",
    "                 autopct='%1.1f%%', colors=colors)\n",
    "    axes[0,0].set_title('감정별 곡 분포', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 2. Valence vs Energy 산점도\n",
    "    emotion_colors = {\n",
    "        'very_sad': '#FF6B6B', 'sad': '#FF8E8E', 'calm': '#4ECDC4',\n",
    "        'happy': '#96CEB4', 'very_happy': '#FFEAA7'\n",
    "    }\n",
    "    \n",
    "    for emotion in self.emotion_categories.keys():\n",
    "        emotion_data = self.df[self.df['emotion_category'] == emotion]\n",
    "        if len(emotion_data) > 0:\n",
    "            axes[0,1].scatter(emotion_data['valence'], emotion_data['energy'], \n",
    "                            c=emotion_colors.get(emotion, 'gray'), \n",
    "                            label=self.emotion_categories[emotion]['label'],\n",
    "                            alpha=0.6, s=10)\n",
    "    \n",
    "    axes[0,1].set_xlabel('Valence (감정가)')\n",
    "    axes[0,1].set_ylabel('Energy (에너지)')\n",
    "    axes[0,1].set_title('Valence vs Energy 분포')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Valence 히스토그램\n",
    "    axes[1,0].hist(self.df['valence'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1,0].axvline(self.df['valence'].mean(), color='red', linestyle='--', \n",
    "                     label=f'평균: {self.df[\"valence\"].mean():.3f}')\n",
    "    axes[1,0].set_xlabel('Valence')\n",
    "    axes[1,0].set_ylabel('빈도')\n",
    "    axes[1,0].set_title('Valence 분포')\n",
    "    axes[1,0].legend()\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. 주요 오디오 특성 박스플롯\n",
    "    audio_features = ['valence', 'energy', 'danceability', 'acousticness']\n",
    "    available_features = [f for f in audio_features if f in self.df.columns]\n",
    "    \n",
    "    box_data = [self.df[feature].values for feature in available_features]\n",
    "    bp = axes[1,1].boxplot(box_data, labels=available_features, patch_artist=True)\n",
    "    \n",
    "    # 박스 색상 설정\n",
    "    box_colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']\n",
    "    for patch, color in zip(bp['boxes'], box_colors[:len(available_features)]):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    axes[1,1].set_title('오디오 특성 분포')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 클래스에 메서드 추가\n",
    "SpotifyEmotionRecommendationSystem._visualize_data_distribution = _visualize_data_distribution\n",
    "\n",
    "print(\" 시각화 메서드 추가 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c01fd31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 모델 훈련 관련 메서드 추가 완료!\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "#  모델 훈련 관련 메서드\n",
    "# ========================================\n",
    "\n",
    "def prepare_training_data(self, test_size=0.2):\n",
    "    \"\"\"모델 훈련용 데이터 준비\"\"\"\n",
    "    if self.df is None:\n",
    "        print(\" 데이터를 먼저 로드해주세요.\")\n",
    "        return None\n",
    "    \n",
    "    # 특성 선택\n",
    "    feature_cols = ['valence', 'energy', 'danceability', 'acousticness', \n",
    "                   'instrumentalness', 'liveness', 'speechiness', 'loudness', 'tempo']\n",
    "    available_features = [col for col in feature_cols if col in self.df.columns]\n",
    "    \n",
    "    print(f\" 사용 특성: {available_features}\")\n",
    "    \n",
    "    # 특성 행렬\n",
    "    X = self.df[available_features].values\n",
    "    \n",
    "    # 타겟 라벨\n",
    "    y = self.df['emotion_category'].values\n",
    "    y_encoded = self.label_encoder.fit_transform(y)\n",
    "    \n",
    "    # 데이터 분할\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_encoded, test_size=test_size, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    # 특성 정규화\n",
    "    X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "    X_test_scaled = self.scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "def _evaluate_model(self, X_test, y_test):\n",
    "    \"\"\"모델 평가\"\"\"\n",
    "    self.emotion_classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = self.emotion_classifier(X_test)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = accuracy_score(y_test.cpu(), predicted.cpu())\n",
    "        \n",
    "        print(f\" 테스트 정확도: {accuracy:.4f}\")\n",
    "        print(\"\\n 상세 분류 리포트:\")\n",
    "        print(classification_report(\n",
    "            y_test.cpu(), \n",
    "            predicted.cpu(),\n",
    "            target_names=[self.emotion_categories[cat]['label'] \n",
    "                         for cat in self.label_encoder.classes_]\n",
    "        ))\n",
    "        \n",
    "        # Confusion Matrix 시각화\n",
    "        cm = confusion_matrix(y_test.cpu(), predicted.cpu())\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=[self.emotion_categories[cat]['label'] for cat in self.label_encoder.classes_],\n",
    "                   yticklabels=[self.emotion_categories[cat]['label'] for cat in self.label_encoder.classes_])\n",
    "        plt.title('감정 분류 Confusion Matrix')\n",
    "        plt.xlabel('예측')\n",
    "        plt.ylabel('실제')\n",
    "        plt.show()\n",
    "        \n",
    "        return accuracy\n",
    "\n",
    "def _plot_training_history(self, losses, accuracies):\n",
    "    \"\"\"훈련 과정 시각화\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss\n",
    "    ax1.plot(losses, color='red', linewidth=2)\n",
    "    ax1.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    ax2.plot(accuracies, color='blue', linewidth=2)\n",
    "    ax2.set_title('Training Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 클래스에 메서드 추가\n",
    "SpotifyEmotionRecommendationSystem.prepare_training_data = prepare_training_data\n",
    "SpotifyEmotionRecommendationSystem._evaluate_model = _evaluate_model\n",
    "SpotifyEmotionRecommendationSystem._plot_training_history = _plot_training_history\n",
    "\n",
    "print(\" 모델 훈련 관련 메서드 추가 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11b315a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 메인 훈련 메서드\n",
    "# ========================================\n",
    "\n",
    "def train_emotion_classifier(self, epochs=100, batch_size=256, lr=0.001):\n",
    "    \"\"\"감정 분류 모델 훈련\"\"\"\n",
    "    print(\"감정 분류 모델 훈련 시작...\")\n",
    "    \n",
    "    # 데이터 준비\n",
    "    data = self.prepare_training_data()\n",
    "    if data is None:\n",
    "        return False\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    \n",
    "    # PyTorch 텐서 변환\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(self.device)\n",
    "    y_train_tensor = torch.LongTensor(y_train).to(self.device)\n",
    "    X_test_tensor = torch.FloatTensor(X_test).to(self.device)\n",
    "    y_test_tensor = torch.LongTensor(y_test).to(self.device)\n",
    "    \n",
    "    # 데이터 로더\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 모델 초기화\n",
    "    input_size = X_train.shape[1]\n",
    "    num_classes = len(self.label_encoder.classes_)\n",
    "    self.emotion_classifier = MusicEmotionClassifier(\n",
    "        input_size=input_size, \n",
    "        num_classes=num_classes\n",
    "    ).to(self.device)\n",
    "    \n",
    "    # 손실 함수와 최적화기\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(self.emotion_classifier.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=15, factor=0.5)\n",
    "    \n",
    "    # 훈련\n",
    "    train_losses, train_accuracies = [], []\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"모델 훈련\"):\n",
    "        self.emotion_classifier.train()\n",
    "        epoch_loss, correct, total = 0, 0, 0\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.emotion_classifier(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient Clipping\n",
    "            torch.nn.utils.clip_grad_norm_(self.emotion_classifier.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        train_losses.append(avg_loss)\n",
    "        train_accuracies.append(accuracy)\n",
    "        scheduler.step(avg_loss)\n",
    "        \n",
    "        # 주기적 출력\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    # 테스트 평가\n",
    "    print(\"\\n테스트 데이터 평가 중...\")\n",
    "    test_accuracy = self._evaluate_model(X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    # 훈련 과정 시각화\n",
    "    self._plot_training_history(train_losses, train_accuracies)\n",
    "    \n",
    "    # 모델 저장\n",
    "    self.save_models()\n",
    "    \n",
    "    return True\n",
    "\n",
    "# 클래스에 메서드 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb0cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0162c3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
